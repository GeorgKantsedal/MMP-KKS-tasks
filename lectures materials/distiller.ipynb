{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "594e5f49",
   "metadata": {
    "papermill": {
     "duration": 0.01975,
     "end_time": "2022-03-26T07:37:07.525682",
     "exception": false,
     "start_time": "2022-03-26T07:37:07.505932",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#  Ubiquant Market Prediction with DNN\n",
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8e4c6eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:37:07.569842Z",
     "iopub.status.busy": "2022-03-26T07:37:07.568327Z",
     "iopub.status.idle": "2022-03-26T07:37:13.137052Z",
     "shell.execute_reply": "2022-03-26T07:37:13.137489Z",
     "shell.execute_reply.started": "2022-03-26T07:22:55.199983Z"
    },
    "papermill": {
     "duration": 5.59192,
     "end_time": "2022-03-26T07:37:13.137807",
     "exception": false,
     "start_time": "2022-03-26T07:37:07.545887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from scipy import stats\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5356e2",
   "metadata": {
    "papermill": {
     "duration": 0.018095,
     "end_time": "2022-03-26T07:37:13.174443",
     "exception": false,
     "start_time": "2022-03-26T07:37:13.156348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5abdf2fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:37:13.214025Z",
     "iopub.status.busy": "2022-03-26T07:37:13.213206Z",
     "iopub.status.idle": "2022-03-26T07:37:27.962555Z",
     "shell.execute_reply": "2022-03-26T07:37:27.963149Z",
     "shell.execute_reply.started": "2022-03-26T07:23:00.511716Z"
    },
    "papermill": {
     "duration": 14.770836,
     "end_time": "2022-03-26T07:37:27.963335",
     "exception": false,
     "start_time": "2022-03-26T07:37:13.192499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 423 ms, sys: 1.6 s, total: 2.03 s\n",
      "Wall time: 14.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>investment_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>...</th>\n",
       "      <th>f_291</th>\n",
       "      <th>f_292</th>\n",
       "      <th>f_293</th>\n",
       "      <th>f_294</th>\n",
       "      <th>f_295</th>\n",
       "      <th>f_296</th>\n",
       "      <th>f_297</th>\n",
       "      <th>f_298</th>\n",
       "      <th>f_299</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.932617</td>\n",
       "      <td>0.113708</td>\n",
       "      <td>-0.402100</td>\n",
       "      <td>0.378418</td>\n",
       "      <td>-0.203979</td>\n",
       "      <td>-0.413574</td>\n",
       "      <td>0.965820</td>\n",
       "      <td>1.230469</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.095703</td>\n",
       "      <td>0.200073</td>\n",
       "      <td>0.819336</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>-0.086792</td>\n",
       "      <td>-1.086914</td>\n",
       "      <td>-1.044922</td>\n",
       "      <td>-0.287598</td>\n",
       "      <td>0.321533</td>\n",
       "      <td>-0.300781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.811035</td>\n",
       "      <td>-0.514160</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>-0.616699</td>\n",
       "      <td>-0.194214</td>\n",
       "      <td>1.771484</td>\n",
       "      <td>1.427734</td>\n",
       "      <td>1.133789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.819336</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>-0.387695</td>\n",
       "      <td>-1.086914</td>\n",
       "      <td>-0.929688</td>\n",
       "      <td>-0.974121</td>\n",
       "      <td>-0.343506</td>\n",
       "      <td>-0.231079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.394043</td>\n",
       "      <td>0.615723</td>\n",
       "      <td>0.567871</td>\n",
       "      <td>-0.607910</td>\n",
       "      <td>0.068909</td>\n",
       "      <td>-1.083008</td>\n",
       "      <td>0.979492</td>\n",
       "      <td>-1.125977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>-0.551758</td>\n",
       "      <td>-1.220703</td>\n",
       "      <td>-1.060547</td>\n",
       "      <td>-0.219116</td>\n",
       "      <td>-1.086914</td>\n",
       "      <td>-0.612305</td>\n",
       "      <td>-0.113953</td>\n",
       "      <td>0.243652</td>\n",
       "      <td>0.568848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.343750</td>\n",
       "      <td>-0.011871</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>-0.606445</td>\n",
       "      <td>-0.586914</td>\n",
       "      <td>-0.815918</td>\n",
       "      <td>0.778320</td>\n",
       "      <td>0.299072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>-0.266357</td>\n",
       "      <td>-1.220703</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>-0.608887</td>\n",
       "      <td>0.104919</td>\n",
       "      <td>-0.783203</td>\n",
       "      <td>1.151367</td>\n",
       "      <td>-0.773438</td>\n",
       "      <td>-1.064453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842285</td>\n",
       "      <td>-0.262939</td>\n",
       "      <td>2.330078</td>\n",
       "      <td>-0.583496</td>\n",
       "      <td>-0.618164</td>\n",
       "      <td>-0.742676</td>\n",
       "      <td>-0.946777</td>\n",
       "      <td>1.230469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>-0.741211</td>\n",
       "      <td>-1.220703</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>-0.588379</td>\n",
       "      <td>0.104919</td>\n",
       "      <td>0.753418</td>\n",
       "      <td>1.345703</td>\n",
       "      <td>-0.737793</td>\n",
       "      <td>-0.531738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   investment_id  time_id       f_0       f_1       f_2       f_3       f_4  \\\n",
       "0              1        0  0.932617  0.113708 -0.402100  0.378418 -0.203979   \n",
       "1              2        0  0.811035 -0.514160  0.742188 -0.616699 -0.194214   \n",
       "2              6        0  0.394043  0.615723  0.567871 -0.607910  0.068909   \n",
       "3              7        0 -2.343750 -0.011871  1.875000 -0.606445 -0.586914   \n",
       "4              8        0  0.842285 -0.262939  2.330078 -0.583496 -0.618164   \n",
       "\n",
       "        f_5       f_6       f_7  ...     f_291     f_292     f_293     f_294  \\\n",
       "0 -0.413574  0.965820  1.230469  ... -1.095703  0.200073  0.819336  0.941406   \n",
       "1  1.771484  1.427734  1.133789  ...  0.912598 -0.734375  0.819336  0.941406   \n",
       "2 -1.083008  0.979492 -1.125977  ...  0.912598 -0.551758 -1.220703 -1.060547   \n",
       "3 -0.815918  0.778320  0.299072  ...  0.912598 -0.266357 -1.220703  0.941406   \n",
       "4 -0.742676 -0.946777  1.230469  ...  0.912598 -0.741211 -1.220703  0.941406   \n",
       "\n",
       "      f_295     f_296     f_297     f_298     f_299    target  \n",
       "0 -0.086792 -1.086914 -1.044922 -0.287598  0.321533 -0.300781  \n",
       "1 -0.387695 -1.086914 -0.929688 -0.974121 -0.343506 -0.231079  \n",
       "2 -0.219116 -1.086914 -0.612305 -0.113953  0.243652  0.568848  \n",
       "3 -0.608887  0.104919 -0.783203  1.151367 -0.773438 -1.064453  \n",
       "4 -0.588379  0.104919  0.753418  1.345703 -0.737793 -0.531738  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "n_features = 300\n",
    "features = [f'f_{i}' for i in range(n_features)]\n",
    "train = pd.read_pickle('../input/ubiquant-market-prediction-half-precision-pickle/train.pkl')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b6de389",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:37:28.007606Z",
     "iopub.status.busy": "2022-03-26T07:37:28.006722Z",
     "iopub.status.idle": "2022-03-26T07:37:28.022724Z",
     "shell.execute_reply": "2022-03-26T07:37:28.023144Z",
     "shell.execute_reply.started": "2022-03-26T07:23:16.536757Z"
    },
    "papermill": {
     "duration": 0.040046,
     "end_time": "2022-03-26T07:37:28.023289",
     "exception": false,
     "start_time": "2022-03-26T07:37:27.983243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    6\n",
       "3    7\n",
       "4    8\n",
       "Name: investment_id, dtype: uint16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "investment_id = train.pop(\"investment_id\")\n",
    "investment_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0930b54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:37:28.073732Z",
     "iopub.status.busy": "2022-03-26T07:37:28.068699Z",
     "iopub.status.idle": "2022-03-26T07:37:28.080682Z",
     "shell.execute_reply": "2022-03-26T07:37:28.080192Z",
     "shell.execute_reply.started": "2022-03-26T07:23:16.554741Z"
    },
    "papermill": {
     "duration": 0.037487,
     "end_time": "2022-03-26T07:37:28.080811",
     "exception": false,
     "start_time": "2022-03-26T07:37:28.043324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = train.pop(\"time_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4839d13a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:37:28.125825Z",
     "iopub.status.busy": "2022-03-26T07:37:28.125046Z",
     "iopub.status.idle": "2022-03-26T07:37:28.135533Z",
     "shell.execute_reply": "2022-03-26T07:37:28.135982Z",
     "shell.execute_reply.started": "2022-03-26T07:23:16.569503Z"
    },
    "papermill": {
     "duration": 0.035201,
     "end_time": "2022-03-26T07:37:28.136120",
     "exception": false,
     "start_time": "2022-03-26T07:37:28.100919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.300781\n",
       "1   -0.231079\n",
       "2    0.568848\n",
       "3   -1.064453\n",
       "4   -0.531738\n",
       "Name: target, dtype: float16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train.pop(\"target\")\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3705e1",
   "metadata": {
    "papermill": {
     "duration": 0.01937,
     "end_time": "2022-03-26T07:37:28.175299",
     "exception": false,
     "start_time": "2022-03-26T07:37:28.155929",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create a IntegerLookup layer for investment_id input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37778942",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:37:28.222859Z",
     "iopub.status.busy": "2022-03-26T07:37:28.222120Z",
     "iopub.status.idle": "2022-03-26T07:37:31.289029Z",
     "shell.execute_reply": "2022-03-26T07:37:31.289646Z",
     "shell.execute_reply.started": "2022-03-26T07:23:16.586208Z"
    },
    "papermill": {
     "duration": 3.094958,
     "end_time": "2022-03-26T07:37:31.289847",
     "exception": false,
     "start_time": "2022-03-26T07:37:28.194889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 07:37:28.314093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-26 07:37:28.457133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-26 07:37:28.457916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-26 07:37:28.459080: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-26 07:37:28.460240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-26 07:37:28.460925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-26 07:37:28.461756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-26 07:37:30.373201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-26 07:37:30.374021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-26 07:37:30.374666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-26 07:37:30.375240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "2022-03-26 07:37:30.824683: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 894 ms, sys: 621 ms, total: 1.51 s\n",
      "Wall time: 3.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "investment_ids = list(investment_id.unique())\n",
    "investment_id_size = len(investment_ids) + 1\n",
    "investment_id_lookup_layer = layers.IntegerLookup(max_tokens=investment_id_size)\n",
    "investment_id_lookup_layer.adapt(pd.DataFrame({\"investment_ids\":investment_ids}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9cac55",
   "metadata": {
    "papermill": {
     "duration": 0.020412,
     "end_time": "2022-03-26T07:37:31.332057",
     "exception": false,
     "start_time": "2022-03-26T07:37:31.311645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Make Tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbf64c7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:37:31.381031Z",
     "iopub.status.busy": "2022-03-26T07:37:31.377071Z",
     "iopub.status.idle": "2022-03-26T07:37:31.382922Z",
     "shell.execute_reply": "2022-03-26T07:37:31.383335Z",
     "shell.execute_reply.started": "2022-03-26T07:23:19.477652Z"
    },
    "papermill": {
     "duration": 0.030423,
     "end_time": "2022-03-26T07:37:31.383486",
     "exception": false,
     "start_time": "2022-03-26T07:37:31.353063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def preprocess(X, y):\n",
    "    return X, y\n",
    "def make_dataset(feature, investment_id, y, batch_size=1024, mode=\"train\"):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(((investment_id, feature), y))\n",
    "    ds = ds.map(preprocess)\n",
    "    if mode == \"train\":\n",
    "        ds = ds.shuffle(2048)\n",
    "    ds = ds.batch(batch_size).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13fbc32",
   "metadata": {
    "papermill": {
     "duration": 0.020446,
     "end_time": "2022-03-26T07:37:31.424688",
     "exception": false,
     "start_time": "2022-03-26T07:37:31.404242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d22adf02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:37:31.489971Z",
     "iopub.status.busy": "2022-03-26T07:37:31.488301Z",
     "iopub.status.idle": "2022-03-26T07:37:31.490546Z",
     "shell.execute_reply": "2022-03-26T07:37:31.490990Z",
     "shell.execute_reply.started": "2022-03-26T07:23:19.494638Z"
    },
    "papermill": {
     "duration": 0.045541,
     "end_time": "2022-03-26T07:37:31.491130",
     "exception": false,
     "start_time": "2022-03-26T07:37:31.445589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    investment_id_inputs = tf.keras.Input((1, ), dtype=tf.uint16)\n",
    "    features_inputs = tf.keras.Input((300, ), dtype=tf.float16)\n",
    "    \n",
    "    investment_id_x = investment_id_lookup_layer(investment_id_inputs)\n",
    "    investment_id_x = layers.Embedding(investment_id_size, 32, input_length=1)(investment_id_x)\n",
    "    investment_id_x = layers.Reshape((-1, ))(investment_id_x)\n",
    "    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n",
    "    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n",
    "    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n",
    "    \n",
    "    feature_x = layers.Dense(256, activation='swish')(features_inputs)\n",
    "    feature_x = layers.Dense(256, activation='swish')(feature_x)\n",
    "    feature_x = layers.Dense(256, activation='swish')(feature_x)\n",
    "    \n",
    "    x = layers.Concatenate(axis=1)([investment_id_x, feature_x])\n",
    "    x = layers.Dense(320, activation='swish', kernel_regularizer=\"l2\")(x)\n",
    "    x = layers.Dense(128, activation='swish', kernel_regularizer=\"l2\")(x)\n",
    "    x = layers.Dense(32, activation='swish', kernel_regularizer=\"l2\")(x)\n",
    "    x = layers.Dense(16, activation='swish', kernel_regularizer=\"l2\")(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    rmse = keras.metrics.RootMeanSquaredError(name=\"rmse\")\n",
    "    model = tf.keras.Model(inputs=[investment_id_inputs, features_inputs], outputs=[output])\n",
    "    model.compile(optimizer=tf.optimizers.Adam(0.00001), loss='mse', metrics=['mse', \"mae\", \"mape\", rmse])\n",
    "    return model\n",
    "\n",
    "def correlation(x, y, axis=-2):\n",
    "    \"\"\"Metric returning the Pearson correlation coefficient of two tensors over some axis, default -2.\"\"\"\n",
    "    x = tf.convert_to_tensor(x)\n",
    "    y = math_ops.cast(y, x.dtype)\n",
    "    n = tf.cast(tf.shape(x)[axis], x.dtype)\n",
    "    xsum = tf.reduce_sum(x, axis=axis)\n",
    "    ysum = tf.reduce_sum(y, axis=axis)\n",
    "    xmean = xsum / n\n",
    "    ymean = ysum / n\n",
    "    xvar = tf.reduce_sum( tf.math.squared_difference(x, xmean), axis=axis)\n",
    "    yvar = tf.reduce_sum( tf.math.squared_difference(y, ymean), axis=axis)\n",
    "    cov = tf.reduce_sum( (x - xmean) * (y - ymean), axis=axis)\n",
    "    corr = cov / tf.sqrt(xvar * yvar)\n",
    "    return corr\n",
    "\n",
    "def get_model2():\n",
    "    investment_id_inputs = tf.keras.Input((1, ), dtype=tf.uint16)\n",
    "    features_inputs = tf.keras.Input((300, ), dtype=tf.float16)\n",
    "    \n",
    "    investment_id_x = investment_id_lookup_layer(investment_id_inputs)\n",
    "    investment_id_x = layers.Embedding(investment_id_size, 32, input_length=1)(investment_id_x)\n",
    "    investment_id_x = layers.Reshape((-1, ))(investment_id_x)\n",
    "#     investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n",
    "#     investment_id_x = layers.Dropout(0.1)(investment_id_x)\n",
    "#     investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n",
    "#     investment_id_x = layers.Dropout(0.1)(investment_id_x)\n",
    "    investment_id_x = layers.Dense(1, activation='swish')(investment_id_x)\n",
    "#     investment_id_x = layers.Dropout(1)(investment_id_x)\n",
    "    \n",
    "    feature_x = layers.Dense(256, activation='swish')(features_inputs)\n",
    "    feature_x = layers.Dropout(0.1)(feature_x)\n",
    "    feature_x = layers.Dense(256, activation='swish')(feature_x)\n",
    "    feature_x = layers.Dropout(0.1)(feature_x)\n",
    "    feature_x = layers.Dense(256, activation='swish')(feature_x)\n",
    "    feature_x = layers.Dropout(0.1)(feature_x)\n",
    "    feature_x = layers.Dense(256, activation='swish')(feature_x)\n",
    "    feature_x = layers.Dropout(0.1)(feature_x)\n",
    "    \n",
    "    x = layers.Concatenate(axis=1)([investment_id_x, feature_x])\n",
    "    x = layers.Dense(512, activation='swish', kernel_regularizer=\"l2\")(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(128, activation='swish', kernel_regularizer=\"l2\")(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(32, activation='swish', kernel_regularizer=\"l2\")(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "#     rmse = keras.metrics.RootMeanSquaredError(name=\"rmse\")\n",
    "    model = tf.keras.Model(inputs=[investment_id_inputs, features_inputs], outputs=[output])\n",
    "#     model.compile(optimizer=tf.optimizers.Adam(0.001), loss='mse', metrics=['mse', \"mae\", \"mape\", rmse, correlation])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3212a21d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:37:31.538194Z",
     "iopub.status.busy": "2022-03-26T07:37:31.537341Z",
     "iopub.status.idle": "2022-03-26T07:37:31.539213Z",
     "shell.execute_reply": "2022-03-26T07:37:31.539659Z",
     "shell.execute_reply.started": "2022-03-26T07:23:19.539821Z"
    },
    "papermill": {
     "duration": 0.026546,
     "end_time": "2022-03-26T07:37:31.539796",
     "exception": false,
     "start_time": "2022-03-26T07:37:31.513250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# student = get_model2()\n",
    "# student.summary()\n",
    "# keras.utils.plot_model(student, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff12e080",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:37:31.740798Z",
     "iopub.status.busy": "2022-03-26T07:37:31.584073Z",
     "iopub.status.idle": "2022-03-26T07:37:31.746630Z",
     "shell.execute_reply": "2022-03-26T07:37:31.746157Z",
     "shell.execute_reply.started": "2022-03-26T07:23:19.552215Z"
    },
    "papermill": {
     "duration": 0.18632,
     "end_time": "2022-03-26T07:37:31.746760",
     "exception": false,
     "start_time": "2022-03-26T07:37:31.560440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "798"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551deaf8",
   "metadata": {
    "papermill": {
     "duration": 0.020649,
     "end_time": "2022-03-26T07:37:31.788355",
     "exception": false,
     "start_time": "2022-03-26T07:37:31.767706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00c48d1e",
   "metadata": {
    "papermill": {
     "duration": 0.020502,
     "end_time": "2022-03-26T07:37:31.829487",
     "exception": false,
     "start_time": "2022-03-26T07:37:31.808985",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "029d51f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:37:31.876120Z",
     "iopub.status.busy": "2022-03-26T07:37:31.875544Z",
     "iopub.status.idle": "2022-03-26T07:37:35.782366Z",
     "shell.execute_reply": "2022-03-26T07:37:35.781902Z",
     "shell.execute_reply.started": "2022-03-26T07:23:19.761504Z"
    },
    "papermill": {
     "duration": 3.932284,
     "end_time": "2022-03-26T07:37:35.782509",
     "exception": false,
     "start_time": "2022-03-26T07:37:31.850225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "teacher = []\n",
    "teacher.append(keras.models.load_model(f\"../input/simple-model-caves/model_43\"))\n",
    "\n",
    "teacher.append(keras.models.load_model(f\"../input/simple-model-caves/model_51\"))\n",
    "\n",
    "teacher.append(keras.models.load_model(f\"../input/simple-model-caves/model_48\"))\n",
    "\n",
    "teacher.append(keras.models.load_model(f\"../input/simple-model-caves/model_42\"))\n",
    "\n",
    "teacher_weights = [0.1, 0.1, 0.35, 0.45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc51817f",
   "metadata": {
    "papermill": {
     "duration": 0.020726,
     "end_time": "2022-03-26T07:37:35.824773",
     "exception": false,
     "start_time": "2022-03-26T07:37:35.804047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "973c9151",
   "metadata": {
    "papermill": {
     "duration": 0.020718,
     "end_time": "2022-03-26T07:37:35.867957",
     "exception": false,
     "start_time": "2022-03-26T07:37:35.847239",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5c622f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:37:35.915892Z",
     "iopub.status.busy": "2022-03-26T07:37:35.915032Z",
     "iopub.status.idle": "2022-03-26T07:37:35.928011Z",
     "shell.execute_reply": "2022-03-26T07:37:35.927583Z",
     "shell.execute_reply.started": "2022-03-26T07:23:23.720943Z"
    },
    "papermill": {
     "duration": 0.038957,
     "end_time": "2022-03-26T07:37:35.928125",
     "exception": false,
     "start_time": "2022-03-26T07:37:35.889168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Distiller(keras.Model):\n",
    "\n",
    "  # Needs both the student and teacher models to create an instance of this class\n",
    "    def __init__(self, student, teacher):\n",
    "        super(Distiller, self).__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "\n",
    "    # Will be used when calling model.compile()\n",
    "    def compile(self, optimizer, metrics, student_loss_fn,\n",
    "              distillation_loss_fn, alpha, temperature):\n",
    "\n",
    "        # Compile using the optimizer and metrics\n",
    "        \n",
    "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "        # Add the other params to the instance\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    # Will be used when calling model.fit()\n",
    "    def train_step(self, data):\n",
    "        # Data is expected to be a tuple of (features, labels)\n",
    "        x, y = data\n",
    "\n",
    "        # Vanilla forward pass of the teacher\n",
    "        # Note that the teacher is NOT trained\n",
    "        teacher_predictions = self.teacher[0](x, training=False)*teacher_weights[0]\n",
    "        for t in range(1, len(self.teacher)):\n",
    "#             teacher_predictions = t(x, training=False)\n",
    "            teacher_predictions = teacher_predictions + self.teacher[t](x, training=False)*teacher_weights[t]\n",
    "            \n",
    "#         tf.math.reduce_mean()\n",
    "\n",
    "        # Use GradientTape to save gradients\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Vanilla forward pass of the student\n",
    "            student_predictions = self.student(x, training=True)\n",
    "\n",
    "            # Compute vanilla student loss\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "\n",
    "            # Compute distillation loss\n",
    "            # Should be KL divergence between logits softened by a temperature factor\n",
    "#             distillation_loss = self.distillation_loss_fn(\n",
    "#                 tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
    "#                 tf.nn.softmax(student_predictions / self.temperature, axis=1))\n",
    "            distillation_loss = self.distillation_loss_fn(teacher_predictions / self.temperature, \n",
    "                                                          student_predictions/self.temperature)\n",
    "\n",
    "            # Compute loss by weighting the two previous losses using the alpha param\n",
    "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
    "\n",
    "        # Use tape to calculate gradients for student\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        # Update student weights \n",
    "        # Note that this done ONLY for the student\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Update the metrics\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "        # Return a performance dictionary\n",
    "        # You will see this being outputted during training\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss, \"distillation_loss\": distillation_loss})\n",
    "        return results\n",
    "\n",
    "\n",
    "    # Will be used when calling model.evaluate()\n",
    "    def test_step(self, data):\n",
    "        # Data is expected to be a tuple of (features, labels)\n",
    "        x, y = data\n",
    "        # Use student to make predictions\n",
    "        # Notice that the training param is set to False\n",
    "        y_prediction = self.student(x, training=False)\n",
    "        # Calculate student's vanilla loss\n",
    "        student_loss = self.student_loss_fn(y, y_prediction)\n",
    "        # Update the metrics\n",
    "        self.compiled_metrics.update_state(y, y_prediction)\n",
    "        # Return a performance dictionary\n",
    "        # You will see this being outputted during inference\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss})\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6779dfdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:37:35.974161Z",
     "iopub.status.busy": "2022-03-26T07:37:35.972587Z",
     "iopub.status.idle": "2022-03-26T07:37:35.974772Z",
     "shell.execute_reply": "2022-03-26T07:37:35.975173Z",
     "shell.execute_reply.started": "2022-03-26T07:23:23.740004Z"
    },
    "papermill": {
     "duration": 0.026517,
     "end_time": "2022-03-26T07:37:35.975292",
     "exception": false,
     "start_time": "2022-03-26T07:37:35.948775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Distiller instance\n",
    "# teacher = keras.models.load_model(f\"../input/simple-model-caves/model_42\")\n",
    "\n",
    "\n",
    "# Distill knowledge from teacher to student (will take around 3 mins with GPU enabled)\n",
    "# distiller_history = distiller.fit(train_batches, epochs=5, validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22637267",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:37:36.021631Z",
     "iopub.status.busy": "2022-03-26T07:37:36.020479Z",
     "iopub.status.idle": "2022-03-26T07:37:36.022297Z",
     "shell.execute_reply": "2022-03-26T07:37:36.022787Z",
     "shell.execute_reply.started": "2022-03-26T07:23:23.752592Z"
    },
    "papermill": {
     "duration": 0.026836,
     "end_time": "2022-03-26T07:37:36.022926",
     "exception": false,
     "start_time": "2022-03-26T07:37:35.996090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(teacher, show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d40f05f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:37:36.074198Z",
     "iopub.status.busy": "2022-03-26T07:37:36.073326Z",
     "iopub.status.idle": "2022-03-26T07:37:36.075543Z",
     "shell.execute_reply": "2022-03-26T07:37:36.075035Z",
     "shell.execute_reply.started": "2022-03-26T07:27:48.060738Z"
    },
    "papermill": {
     "duration": 0.031489,
     "end_time": "2022-03-26T07:37:36.075672",
     "exception": false,
     "start_time": "2022-03-26T07:37:36.044183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(student, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d7e38f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:37:36.127799Z",
     "iopub.status.busy": "2022-03-26T07:37:36.127087Z",
     "iopub.status.idle": "2022-03-26T11:13:58.963801Z",
     "shell.execute_reply": "2022-03-26T11:13:58.963303Z",
     "shell.execute_reply.started": "2022-03-26T07:27:48.317356Z"
    },
    "papermill": {
     "duration": 12982.86783,
     "end_time": "2022-03-26T11:13:58.964709",
     "exception": false,
     "start_time": "2022-03-26T07:37:36.096879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "2022-03-26 07:37:49.963426: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1256563800 exceeds 10% of free system memory.\n",
      "2022-03-26 07:37:51.252766: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1256563800 exceeds 10% of free system memory.\n",
      "2022-03-26 07:37:53.896759: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1256563800 exceeds 10% of free system memory.\n",
      "2022-03-26 07:37:54.668702: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1256563800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/140\n",
      "2046/2046 [==============================] - 29s 13ms/step - rmse: 0.9090 - correlation: 0.1447 - student_loss: 0.8264 - distillation_loss: 0.0021 - val_rmse: 0.9182 - val_correlation: 0.1218 - val_student_loss: 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 07:38:24.361345: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1256563800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9082 - correlation: 0.1503 - student_loss: 0.8250 - distillation_loss: 0.0013 - val_rmse: 0.9175 - val_correlation: 0.1269 - val_student_loss: 0.8701\n",
      "Epoch 3/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9079 - correlation: 0.1529 - student_loss: 0.8244 - distillation_loss: 0.0011 - val_rmse: 0.9181 - val_correlation: 0.1230 - val_student_loss: 0.8758\n",
      "Epoch 4/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9077 - correlation: 0.1545 - student_loss: 0.8240 - distillation_loss: 0.0010 - val_rmse: 0.9177 - val_correlation: 0.1257 - val_student_loss: 0.8671\n",
      "Epoch 5/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9075 - correlation: 0.1557 - student_loss: 0.8237 - distillation_loss: 9.9308e-04 - val_rmse: 0.9185 - val_correlation: 0.1224 - val_student_loss: 0.8661\n",
      "Epoch 6/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9073 - correlation: 0.1572 - student_loss: 0.8232 - distillation_loss: 9.4217e-04 - val_rmse: 0.9172 - val_correlation: 0.1304 - val_student_loss: 0.8636\n",
      "Epoch 7/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9071 - correlation: 0.1586 - student_loss: 0.8230 - distillation_loss: 9.2186e-04 - val_rmse: 0.9172 - val_correlation: 0.1305 - val_student_loss: 0.8656\n",
      "Epoch 8/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9070 - correlation: 0.1596 - student_loss: 0.8227 - distillation_loss: 8.9223e-04 - val_rmse: 0.9167 - val_correlation: 0.1333 - val_student_loss: 0.8683\n",
      "Epoch 9/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9068 - correlation: 0.1606 - student_loss: 0.8225 - distillation_loss: 7.3831e-04 - val_rmse: 0.9165 - val_correlation: 0.1354 - val_student_loss: 0.8650\n",
      "Epoch 10/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9067 - correlation: 0.1618 - student_loss: 0.8222 - distillation_loss: 7.1690e-04 - val_rmse: 0.9161 - val_correlation: 0.1383 - val_student_loss: 0.8673\n",
      "Epoch 11/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9065 - correlation: 0.1629 - student_loss: 0.8219 - distillation_loss: 7.0046e-04 - val_rmse: 0.9160 - val_correlation: 0.1389 - val_student_loss: 0.8675\n",
      "Epoch 12/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9064 - correlation: 0.1638 - student_loss: 0.8216 - distillation_loss: 6.8162e-04 - val_rmse: 0.9162 - val_correlation: 0.1371 - val_student_loss: 0.8644\n",
      "Epoch 13/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9063 - correlation: 0.1646 - student_loss: 0.8215 - distillation_loss: 6.8268e-04 - val_rmse: 0.9159 - val_correlation: 0.1396 - val_student_loss: 0.8666\n",
      "Epoch 14/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9061 - correlation: 0.1656 - student_loss: 0.8211 - distillation_loss: 6.7469e-04 - val_rmse: 0.9159 - val_correlation: 0.1400 - val_student_loss: 0.8649\n",
      "Epoch 15/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9060 - correlation: 0.1661 - student_loss: 0.8211 - distillation_loss: 6.6323e-04 - val_rmse: 0.9158 - val_correlation: 0.1410 - val_student_loss: 0.8665\n",
      "Epoch 16/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9059 - correlation: 0.1670 - student_loss: 0.8208 - distillation_loss: 6.6397e-04 - val_rmse: 0.9161 - val_correlation: 0.1387 - val_student_loss: 0.8683\n",
      "Epoch 17/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9059 - correlation: 0.1675 - student_loss: 0.8207 - distillation_loss: 5.9718e-04 - val_rmse: 0.9161 - val_correlation: 0.1389 - val_student_loss: 0.8701\n",
      "Epoch 18/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1685 - student_loss: 0.8205 - distillation_loss: 5.9874e-04 - val_rmse: 0.9160 - val_correlation: 0.1389 - val_student_loss: 0.8695\n",
      "Epoch 19/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1690 - student_loss: 0.8204 - distillation_loss: 5.9137e-04 - val_rmse: 0.9162 - val_correlation: 0.1382 - val_student_loss: 0.8735\n",
      "Epoch 20/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9056 - correlation: 0.1694 - student_loss: 0.8202 - distillation_loss: 5.8519e-04 - val_rmse: 0.9161 - val_correlation: 0.1390 - val_student_loss: 0.8702\n",
      "Epoch 21/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9055 - correlation: 0.1701 - student_loss: 0.8200 - distillation_loss: 5.8708e-04 - val_rmse: 0.9159 - val_correlation: 0.1402 - val_student_loss: 0.8691\n",
      "Epoch 22/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9054 - correlation: 0.1708 - student_loss: 0.8198 - distillation_loss: 5.8304e-04 - val_rmse: 0.9160 - val_correlation: 0.1393 - val_student_loss: 0.8694\n",
      "Epoch 23/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9054 - correlation: 0.1710 - student_loss: 0.8198 - distillation_loss: 5.8229e-04 - val_rmse: 0.9159 - val_correlation: 0.1406 - val_student_loss: 0.8698\n",
      "Epoch 24/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9053 - correlation: 0.1716 - student_loss: 0.8196 - distillation_loss: 5.8575e-04 - val_rmse: 0.9161 - val_correlation: 0.1396 - val_student_loss: 0.8719\n",
      "Epoch 25/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9052 - correlation: 0.1720 - student_loss: 0.8195 - distillation_loss: 5.4743e-04 - val_rmse: 0.9158 - val_correlation: 0.1407 - val_student_loss: 0.8692\n",
      "Epoch 26/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9052 - correlation: 0.1721 - student_loss: 0.8195 - distillation_loss: 5.4657e-04 - val_rmse: 0.9158 - val_correlation: 0.1412 - val_student_loss: 0.8704\n",
      "Epoch 27/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9051 - correlation: 0.1727 - student_loss: 0.8193 - distillation_loss: 5.4288e-04 - val_rmse: 0.9159 - val_correlation: 0.1407 - val_student_loss: 0.8696\n",
      "Epoch 28/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9051 - correlation: 0.1729 - student_loss: 0.8193 - distillation_loss: 5.4604e-04 - val_rmse: 0.9159 - val_correlation: 0.1399 - val_student_loss: 0.8683\n",
      "Epoch 29/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9050 - correlation: 0.1734 - student_loss: 0.8192 - distillation_loss: 5.4401e-04 - val_rmse: 0.9157 - val_correlation: 0.1422 - val_student_loss: 0.8687\n",
      "Epoch 30/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9050 - correlation: 0.1734 - student_loss: 0.8192 - distillation_loss: 5.4074e-04 - val_rmse: 0.9158 - val_correlation: 0.1406 - val_student_loss: 0.8696\n",
      "Epoch 31/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9049 - correlation: 0.1739 - student_loss: 0.8190 - distillation_loss: 5.4263e-04 - val_rmse: 0.9158 - val_correlation: 0.1410 - val_student_loss: 0.8691\n",
      "Epoch 32/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9049 - correlation: 0.1740 - student_loss: 0.8190 - distillation_loss: 5.3634e-04 - val_rmse: 0.9157 - val_correlation: 0.1417 - val_student_loss: 0.8680\n",
      "Epoch 33/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9049 - correlation: 0.1740 - student_loss: 0.8190 - distillation_loss: 5.2588e-04 - val_rmse: 0.9156 - val_correlation: 0.1426 - val_student_loss: 0.8684\n",
      "Epoch 34/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9049 - correlation: 0.1742 - student_loss: 0.8189 - distillation_loss: 5.2048e-04 - val_rmse: 0.9156 - val_correlation: 0.1425 - val_student_loss: 0.8687\n",
      "Epoch 35/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9048 - correlation: 0.1745 - student_loss: 0.8189 - distillation_loss: 5.2345e-04 - val_rmse: 0.9156 - val_correlation: 0.1422 - val_student_loss: 0.8676\n",
      "Epoch 36/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9048 - correlation: 0.1748 - student_loss: 0.8188 - distillation_loss: 5.2310e-04 - val_rmse: 0.9156 - val_correlation: 0.1431 - val_student_loss: 0.8683\n",
      "Epoch 37/140\n",
      "2046/2046 [==============================] - 23s 11ms/step - rmse: 0.9048 - correlation: 0.1748 - student_loss: 0.8188 - distillation_loss: 5.2114e-04 - val_rmse: 0.9156 - val_correlation: 0.1427 - val_student_loss: 0.8693\n",
      "Epoch 38/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9048 - correlation: 0.1748 - student_loss: 0.8188 - distillation_loss: 5.2145e-04 - val_rmse: 0.9156 - val_correlation: 0.1422 - val_student_loss: 0.8676\n",
      "Epoch 39/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9047 - correlation: 0.1753 - student_loss: 0.8186 - distillation_loss: 5.2006e-04 - val_rmse: 0.9156 - val_correlation: 0.1430 - val_student_loss: 0.8683\n",
      "Epoch 40/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9048 - correlation: 0.1750 - student_loss: 0.8187 - distillation_loss: 5.1913e-04 - val_rmse: 0.9155 - val_correlation: 0.1433 - val_student_loss: 0.8688\n",
      "Epoch 41/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9047 - correlation: 0.1753 - student_loss: 0.8187 - distillation_loss: 5.1373e-04 - val_rmse: 0.9156 - val_correlation: 0.1429 - val_student_loss: 0.8687\n",
      "Epoch 42/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9047 - correlation: 0.1754 - student_loss: 0.8186 - distillation_loss: 5.0899e-04 - val_rmse: 0.9156 - val_correlation: 0.1430 - val_student_loss: 0.8684\n",
      "Epoch 43/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9047 - correlation: 0.1757 - student_loss: 0.8186 - distillation_loss: 5.0977e-04 - val_rmse: 0.9155 - val_correlation: 0.1435 - val_student_loss: 0.8686\n",
      "Epoch 44/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9047 - correlation: 0.1756 - student_loss: 0.8186 - distillation_loss: 5.0596e-04 - val_rmse: 0.9156 - val_correlation: 0.1430 - val_student_loss: 0.8683\n",
      "Epoch 45/140\n",
      "2046/2046 [==============================] - 23s 11ms/step - rmse: 0.9047 - correlation: 0.1755 - student_loss: 0.8186 - distillation_loss: 5.1206e-04 - val_rmse: 0.9155 - val_correlation: 0.1435 - val_student_loss: 0.8682\n",
      "Epoch 46/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1761 - student_loss: 0.8185 - distillation_loss: 5.0924e-04 - val_rmse: 0.9155 - val_correlation: 0.1434 - val_student_loss: 0.8685\n",
      "Epoch 47/140\n",
      "2046/2046 [==============================] - 23s 11ms/step - rmse: 0.9047 - correlation: 0.1757 - student_loss: 0.8186 - distillation_loss: 5.0740e-04 - val_rmse: 0.9156 - val_correlation: 0.1432 - val_student_loss: 0.8681\n",
      "Epoch 48/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9047 - correlation: 0.1758 - student_loss: 0.8185 - distillation_loss: 5.1208e-04 - val_rmse: 0.9156 - val_correlation: 0.1428 - val_student_loss: 0.8686\n",
      "Epoch 49/140\n",
      "2046/2046 [==============================] - 23s 11ms/step - rmse: 0.9047 - correlation: 0.1759 - student_loss: 0.8185 - distillation_loss: 5.0199e-04 - val_rmse: 0.9156 - val_correlation: 0.1431 - val_student_loss: 0.8683\n",
      "Epoch 50/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9047 - correlation: 0.1759 - student_loss: 0.8185 - distillation_loss: 4.9995e-04 - val_rmse: 0.9155 - val_correlation: 0.1433 - val_student_loss: 0.8684\n",
      "Epoch 51/140\n",
      "2046/2046 [==============================] - 23s 11ms/step - rmse: 0.9046 - correlation: 0.1760 - student_loss: 0.8185 - distillation_loss: 5.0395e-04 - val_rmse: 0.9155 - val_correlation: 0.1436 - val_student_loss: 0.8681\n",
      "Epoch 52/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9047 - correlation: 0.1759 - student_loss: 0.8186 - distillation_loss: 5.0175e-04 - val_rmse: 0.9155 - val_correlation: 0.1433 - val_student_loss: 0.8681\n",
      "Epoch 53/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1760 - student_loss: 0.8185 - distillation_loss: 5.0309e-04 - val_rmse: 0.9155 - val_correlation: 0.1433 - val_student_loss: 0.8682\n",
      "Epoch 54/140\n",
      "2046/2046 [==============================] - 23s 11ms/step - rmse: 0.9046 - correlation: 0.1761 - student_loss: 0.8185 - distillation_loss: 5.0164e-04 - val_rmse: 0.9155 - val_correlation: 0.1434 - val_student_loss: 0.8687\n",
      "Epoch 55/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8184 - distillation_loss: 5.0292e-04 - val_rmse: 0.9155 - val_correlation: 0.1437 - val_student_loss: 0.8684\n",
      "Epoch 56/140\n",
      "2046/2046 [==============================] - 23s 11ms/step - rmse: 0.9046 - correlation: 0.1761 - student_loss: 0.8185 - distillation_loss: 5.0267e-04 - val_rmse: 0.9155 - val_correlation: 0.1436 - val_student_loss: 0.8683\n",
      "Epoch 57/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9046 - correlation: 0.1761 - student_loss: 0.8185 - distillation_loss: 5.0132e-04 - val_rmse: 0.9154 - val_correlation: 0.1444 - val_student_loss: 0.8680\n",
      "Epoch 58/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 5.0157e-04 - val_rmse: 0.9154 - val_correlation: 0.1444 - val_student_loss: 0.8680\n",
      "Epoch 59/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9807e-04 - val_rmse: 0.9154 - val_correlation: 0.1444 - val_student_loss: 0.8681\n",
      "Epoch 60/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9611e-04 - val_rmse: 0.9154 - val_correlation: 0.1444 - val_student_loss: 0.8681\n",
      "Epoch 61/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8184 - distillation_loss: 4.9874e-04 - val_rmse: 0.9154 - val_correlation: 0.1445 - val_student_loss: 0.8681\n",
      "Epoch 62/140\n",
      "2046/2046 [==============================] - 23s 11ms/step - rmse: 0.9046 - correlation: 0.1761 - student_loss: 0.8185 - distillation_loss: 4.9830e-04 - val_rmse: 0.9154 - val_correlation: 0.1445 - val_student_loss: 0.8682\n",
      "Epoch 63/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9700e-04 - val_rmse: 0.9154 - val_correlation: 0.1445 - val_student_loss: 0.8679\n",
      "Epoch 64/140\n",
      "2046/2046 [==============================] - 24s 12ms/step - rmse: 0.9046 - correlation: 0.1760 - student_loss: 0.8185 - distillation_loss: 4.9740e-04 - val_rmse: 0.9154 - val_correlation: 0.1447 - val_student_loss: 0.8678\n",
      "Epoch 65/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1760 - student_loss: 0.8185 - distillation_loss: 4.9942e-04 - val_rmse: 0.9153 - val_correlation: 0.1453 - val_student_loss: 0.8680\n",
      "Epoch 66/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9927e-04 - val_rmse: 0.9153 - val_correlation: 0.1454 - val_student_loss: 0.8681\n",
      "Epoch 67/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8184 - distillation_loss: 5.0004e-04 - val_rmse: 0.9153 - val_correlation: 0.1454 - val_student_loss: 0.8682\n",
      "Epoch 68/140\n",
      "2046/2046 [==============================] - 23s 11ms/step - rmse: 0.9046 - correlation: 0.1764 - student_loss: 0.8184 - distillation_loss: 4.9730e-04 - val_rmse: 0.9153 - val_correlation: 0.1455 - val_student_loss: 0.8681\n",
      "Epoch 69/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1765 - student_loss: 0.8184 - distillation_loss: 4.9760e-04 - val_rmse: 0.9153 - val_correlation: 0.1453 - val_student_loss: 0.8681\n",
      "Epoch 70/140\n",
      "2046/2046 [==============================] - 24s 12ms/step - rmse: 0.9046 - correlation: 0.1764 - student_loss: 0.8184 - distillation_loss: 4.9557e-04 - val_rmse: 0.9153 - val_correlation: 0.1455 - val_student_loss: 0.8681\n",
      "Epoch 71/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9519e-04 - val_rmse: 0.9153 - val_correlation: 0.1454 - val_student_loss: 0.8681\n",
      "Epoch 72/140\n",
      "2046/2046 [==============================] - 24s 12ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8184 - distillation_loss: 4.9883e-04 - val_rmse: 0.9153 - val_correlation: 0.1454 - val_student_loss: 0.8682\n",
      "Epoch 73/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9794e-04 - val_rmse: 0.9152 - val_correlation: 0.1458 - val_student_loss: 0.8682\n",
      "Epoch 74/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9810e-04 - val_rmse: 0.9152 - val_correlation: 0.1458 - val_student_loss: 0.8681\n",
      "Epoch 75/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8184 - distillation_loss: 5.0035e-04 - val_rmse: 0.9152 - val_correlation: 0.1458 - val_student_loss: 0.8682\n",
      "Epoch 76/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1764 - student_loss: 0.8184 - distillation_loss: 4.9725e-04 - val_rmse: 0.9152 - val_correlation: 0.1460 - val_student_loss: 0.8682\n",
      "Epoch 77/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1764 - student_loss: 0.8184 - distillation_loss: 4.9740e-04 - val_rmse: 0.9152 - val_correlation: 0.1459 - val_student_loss: 0.8682\n",
      "Epoch 78/140\n",
      "2046/2046 [==============================] - 24s 12ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8184 - distillation_loss: 4.9782e-04 - val_rmse: 0.9152 - val_correlation: 0.1460 - val_student_loss: 0.8681\n",
      "Epoch 79/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8184 - distillation_loss: 4.9406e-04 - val_rmse: 0.9152 - val_correlation: 0.1458 - val_student_loss: 0.8681\n",
      "Epoch 80/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9558e-04 - val_rmse: 0.9152 - val_correlation: 0.1459 - val_student_loss: 0.8681\n",
      "Epoch 81/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8185 - distillation_loss: 4.9388e-04 - val_rmse: 0.9152 - val_correlation: 0.1463 - val_student_loss: 0.8682\n",
      "Epoch 82/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1761 - student_loss: 0.8185 - distillation_loss: 4.9556e-04 - val_rmse: 0.9152 - val_correlation: 0.1464 - val_student_loss: 0.8682\n",
      "Epoch 83/140\n",
      "2046/2046 [==============================] - 23s 11ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9562e-04 - val_rmse: 0.9152 - val_correlation: 0.1464 - val_student_loss: 0.8682\n",
      "Epoch 84/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8184 - distillation_loss: 4.9494e-04 - val_rmse: 0.9152 - val_correlation: 0.1463 - val_student_loss: 0.8681\n",
      "Epoch 85/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1761 - student_loss: 0.8185 - distillation_loss: 4.9509e-04 - val_rmse: 0.9152 - val_correlation: 0.1465 - val_student_loss: 0.8682\n",
      "Epoch 86/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8185 - distillation_loss: 4.9711e-04 - val_rmse: 0.9152 - val_correlation: 0.1465 - val_student_loss: 0.8682\n",
      "Epoch 87/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1764 - student_loss: 0.8184 - distillation_loss: 4.9749e-04 - val_rmse: 0.9152 - val_correlation: 0.1464 - val_student_loss: 0.8681\n",
      "Epoch 88/140\n",
      "2046/2046 [==============================] - 25s 12ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9703e-04 - val_rmse: 0.9152 - val_correlation: 0.1464 - val_student_loss: 0.8682\n",
      "Epoch 89/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9047 - correlation: 0.1760 - student_loss: 0.8185 - distillation_loss: 4.9308e-04 - val_rmse: 0.9151 - val_correlation: 0.1469 - val_student_loss: 0.8683\n",
      "Epoch 90/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8185 - distillation_loss: 4.9611e-04 - val_rmse: 0.9151 - val_correlation: 0.1469 - val_student_loss: 0.8682\n",
      "Epoch 91/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1761 - student_loss: 0.8185 - distillation_loss: 4.9737e-04 - val_rmse: 0.9151 - val_correlation: 0.1469 - val_student_loss: 0.8682\n",
      "Epoch 92/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1764 - student_loss: 0.8184 - distillation_loss: 4.9602e-04 - val_rmse: 0.9151 - val_correlation: 0.1469 - val_student_loss: 0.8683\n",
      "Epoch 93/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9046 - correlation: 0.1765 - student_loss: 0.8184 - distillation_loss: 4.9703e-04 - val_rmse: 0.9151 - val_correlation: 0.1469 - val_student_loss: 0.8683\n",
      "Epoch 94/140\n",
      "2046/2046 [==============================] - 23s 11ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8185 - distillation_loss: 4.9525e-04 - val_rmse: 0.9151 - val_correlation: 0.1469 - val_student_loss: 0.8682\n",
      "Epoch 95/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9360e-04 - val_rmse: 0.9151 - val_correlation: 0.1469 - val_student_loss: 0.8682\n",
      "Epoch 96/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8185 - distillation_loss: 4.9651e-04 - val_rmse: 0.9151 - val_correlation: 0.1469 - val_student_loss: 0.8682\n",
      "Epoch 97/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8185 - distillation_loss: 4.9864e-04 - val_rmse: 0.9151 - val_correlation: 0.1471 - val_student_loss: 0.8683\n",
      "Epoch 98/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9553e-04 - val_rmse: 0.9151 - val_correlation: 0.1471 - val_student_loss: 0.8683\n",
      "Epoch 99/140\n",
      "2046/2046 [==============================] - 26s 13ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8185 - distillation_loss: 4.9850e-04 - val_rmse: 0.9151 - val_correlation: 0.1472 - val_student_loss: 0.8683\n",
      "Epoch 100/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9654e-04 - val_rmse: 0.9151 - val_correlation: 0.1472 - val_student_loss: 0.8683\n",
      "Epoch 101/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9661e-04 - val_rmse: 0.9151 - val_correlation: 0.1472 - val_student_loss: 0.8683\n",
      "Epoch 102/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1761 - student_loss: 0.8185 - distillation_loss: 4.9350e-04 - val_rmse: 0.9151 - val_correlation: 0.1472 - val_student_loss: 0.8683\n",
      "Epoch 103/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8184 - distillation_loss: 4.9547e-04 - val_rmse: 0.9151 - val_correlation: 0.1472 - val_student_loss: 0.8683\n",
      "Epoch 104/140\n",
      "2046/2046 [==============================] - 24s 11ms/step - rmse: 0.9046 - correlation: 0.1764 - student_loss: 0.8184 - distillation_loss: 4.9890e-04 - val_rmse: 0.9151 - val_correlation: 0.1472 - val_student_loss: 0.8683\n",
      "Epoch 105/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9046 - correlation: 0.1761 - student_loss: 0.8185 - distillation_loss: 4.9579e-04 - val_rmse: 0.9151 - val_correlation: 0.1472 - val_student_loss: 0.8683\n",
      "Epoch 106/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9047 - correlation: 0.1760 - student_loss: 0.8185 - distillation_loss: 4.9390e-04 - val_rmse: 0.9151 - val_correlation: 0.1472 - val_student_loss: 0.8684\n",
      "Epoch 107/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9467e-04 - val_rmse: 0.9151 - val_correlation: 0.1473 - val_student_loss: 0.8684\n",
      "Epoch 108/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1761 - student_loss: 0.8185 - distillation_loss: 4.9745e-04 - val_rmse: 0.9151 - val_correlation: 0.1473 - val_student_loss: 0.8684\n",
      "Epoch 109/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1761 - student_loss: 0.8185 - distillation_loss: 4.9619e-04 - val_rmse: 0.9151 - val_correlation: 0.1473 - val_student_loss: 0.8684\n",
      "Epoch 110/140\n",
      "2046/2046 [==============================] - 26s 13ms/step - rmse: 0.9046 - correlation: 0.1764 - student_loss: 0.8184 - distillation_loss: 4.9621e-04 - val_rmse: 0.9151 - val_correlation: 0.1473 - val_student_loss: 0.8684\n",
      "Epoch 111/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1761 - student_loss: 0.8185 - distillation_loss: 4.9550e-04 - val_rmse: 0.9151 - val_correlation: 0.1473 - val_student_loss: 0.8684\n",
      "Epoch 112/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9526e-04 - val_rmse: 0.9151 - val_correlation: 0.1473 - val_student_loss: 0.8684\n",
      "Epoch 113/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9382e-04 - val_rmse: 0.9151 - val_correlation: 0.1473 - val_student_loss: 0.8684\n",
      "Epoch 114/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9432e-04 - val_rmse: 0.9151 - val_correlation: 0.1473 - val_student_loss: 0.8684\n",
      "Epoch 115/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1764 - student_loss: 0.8184 - distillation_loss: 4.9699e-04 - val_rmse: 0.9151 - val_correlation: 0.1473 - val_student_loss: 0.8684\n",
      "Epoch 116/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8185 - distillation_loss: 4.9646e-04 - val_rmse: 0.9151 - val_correlation: 0.1473 - val_student_loss: 0.8684\n",
      "Epoch 117/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1761 - student_loss: 0.8185 - distillation_loss: 4.9706e-04 - val_rmse: 0.9151 - val_correlation: 0.1473 - val_student_loss: 0.8684\n",
      "Epoch 118/140\n",
      "2046/2046 [==============================] - 24s 12ms/step - rmse: 0.9046 - correlation: 0.1764 - student_loss: 0.8184 - distillation_loss: 4.9520e-04 - val_rmse: 0.9151 - val_correlation: 0.1473 - val_student_loss: 0.8684\n",
      "Epoch 119/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1761 - student_loss: 0.8185 - distillation_loss: 4.9715e-04 - val_rmse: 0.9151 - val_correlation: 0.1473 - val_student_loss: 0.8684\n",
      "Epoch 120/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1764 - student_loss: 0.8184 - distillation_loss: 4.9850e-04 - val_rmse: 0.9151 - val_correlation: 0.1473 - val_student_loss: 0.8684\n",
      "Epoch 121/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1761 - student_loss: 0.8185 - distillation_loss: 4.9683e-04 - val_rmse: 0.9151 - val_correlation: 0.1473 - val_student_loss: 0.8684\n",
      "Epoch 122/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1761 - student_loss: 0.8185 - distillation_loss: 4.9470e-04 - val_rmse: 0.9151 - val_correlation: 0.1473 - val_student_loss: 0.8684\n",
      "Epoch 123/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9965e-04 - val_rmse: 0.9151 - val_correlation: 0.1473 - val_student_loss: 0.8684\n",
      "Epoch 124/140\n",
      "2046/2046 [==============================] - 27s 13ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8185 - distillation_loss: 4.9843e-04 - val_rmse: 0.9151 - val_correlation: 0.1473 - val_student_loss: 0.8684\n",
      "Epoch 125/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9619e-04 - val_rmse: 0.9151 - val_correlation: 0.1473 - val_student_loss: 0.8684\n",
      "Epoch 126/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1760 - student_loss: 0.8185 - distillation_loss: 4.9714e-04 - val_rmse: 0.9151 - val_correlation: 0.1474 - val_student_loss: 0.8684\n",
      "Epoch 127/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9632e-04 - val_rmse: 0.9151 - val_correlation: 0.1474 - val_student_loss: 0.8684\n",
      "Epoch 128/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9246e-04 - val_rmse: 0.9151 - val_correlation: 0.1474 - val_student_loss: 0.8684\n",
      "Epoch 129/140\n",
      "2046/2046 [==============================] - 26s 13ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8184 - distillation_loss: 4.9696e-04 - val_rmse: 0.9151 - val_correlation: 0.1474 - val_student_loss: 0.8684\n",
      "Epoch 130/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8184 - distillation_loss: 4.9759e-04 - val_rmse: 0.9151 - val_correlation: 0.1474 - val_student_loss: 0.8684\n",
      "Epoch 131/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9624e-04 - val_rmse: 0.9151 - val_correlation: 0.1474 - val_student_loss: 0.8684\n",
      "Epoch 132/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1764 - student_loss: 0.8185 - distillation_loss: 4.9639e-04 - val_rmse: 0.9151 - val_correlation: 0.1474 - val_student_loss: 0.8684\n",
      "Epoch 133/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9555e-04 - val_rmse: 0.9151 - val_correlation: 0.1474 - val_student_loss: 0.8684\n",
      "Epoch 134/140\n",
      "2046/2046 [==============================] - 19s 9ms/step - rmse: 0.9046 - correlation: 0.1762 - student_loss: 0.8185 - distillation_loss: 4.9769e-04 - val_rmse: 0.9151 - val_correlation: 0.1474 - val_student_loss: 0.8684\n",
      "Epoch 135/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1761 - student_loss: 0.8185 - distillation_loss: 4.9437e-04 - val_rmse: 0.9151 - val_correlation: 0.1474 - val_student_loss: 0.8684\n",
      "Epoch 136/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8184 - distillation_loss: 4.9671e-04 - val_rmse: 0.9151 - val_correlation: 0.1474 - val_student_loss: 0.8684\n",
      "Epoch 137/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8184 - distillation_loss: 4.9644e-04 - val_rmse: 0.9151 - val_correlation: 0.1474 - val_student_loss: 0.8684\n",
      "Epoch 138/140\n",
      "2046/2046 [==============================] - 27s 13ms/step - rmse: 0.9046 - correlation: 0.1761 - student_loss: 0.8185 - distillation_loss: 4.9467e-04 - val_rmse: 0.9151 - val_correlation: 0.1474 - val_student_loss: 0.8684\n",
      "Epoch 139/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8184 - distillation_loss: 4.9548e-04 - val_rmse: 0.9151 - val_correlation: 0.1474 - val_student_loss: 0.8684\n",
      "Epoch 140/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9046 - correlation: 0.1763 - student_loss: 0.8185 - distillation_loss: 4.9591e-04 - val_rmse: 0.9151 - val_correlation: 0.1474 - val_student_loss: 0.8684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 08:45:37.741899: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson: 0.14935313909460374\n",
      "Epoch 1/140\n",
      "2046/2046 [==============================] - 29s 13ms/step - rmse: 0.9101 - correlation: 0.1437 - student_loss: 0.8286 - distillation_loss: 0.0021 - val_rmse: 0.9161 - val_correlation: 0.1264 - val_student_loss: 0.8958\n",
      "Epoch 2/140\n",
      "2046/2046 [==============================] - 24s 12ms/step - rmse: 0.9092 - correlation: 0.1501 - student_loss: 0.8270 - distillation_loss: 0.0012 - val_rmse: 0.9158 - val_correlation: 0.1275 - val_student_loss: 0.8968\n",
      "Epoch 3/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9089 - correlation: 0.1522 - student_loss: 0.8265 - distillation_loss: 0.0011 - val_rmse: 0.9159 - val_correlation: 0.1280 - val_student_loss: 0.9024\n",
      "Epoch 4/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9087 - correlation: 0.1543 - student_loss: 0.8259 - distillation_loss: 0.0010 - val_rmse: 0.9153 - val_correlation: 0.1314 - val_student_loss: 0.8970\n",
      "Epoch 5/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9084 - correlation: 0.1560 - student_loss: 0.8255 - distillation_loss: 9.7985e-04 - val_rmse: 0.9155 - val_correlation: 0.1295 - val_student_loss: 0.9014\n",
      "Epoch 6/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9083 - correlation: 0.1571 - student_loss: 0.8252 - distillation_loss: 9.2151e-04 - val_rmse: 0.9145 - val_correlation: 0.1363 - val_student_loss: 0.8965\n",
      "Epoch 7/140\n",
      "2046/2046 [==============================] - 25s 12ms/step - rmse: 0.9082 - correlation: 0.1576 - student_loss: 0.8251 - distillation_loss: 9.1306e-04 - val_rmse: 0.9152 - val_correlation: 0.1325 - val_student_loss: 0.8985\n",
      "Epoch 8/140\n",
      "2046/2046 [==============================] - 24s 12ms/step - rmse: 0.9080 - correlation: 0.1592 - student_loss: 0.8247 - distillation_loss: 8.8495e-04 - val_rmse: 0.9148 - val_correlation: 0.1346 - val_student_loss: 0.8995\n",
      "Epoch 9/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9079 - correlation: 0.1597 - student_loss: 0.8246 - distillation_loss: 7.3918e-04 - val_rmse: 0.9142 - val_correlation: 0.1394 - val_student_loss: 0.8977\n",
      "Epoch 10/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9077 - correlation: 0.1613 - student_loss: 0.8242 - distillation_loss: 7.1365e-04 - val_rmse: 0.9144 - val_correlation: 0.1382 - val_student_loss: 0.8988\n",
      "Epoch 11/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9075 - correlation: 0.1622 - student_loss: 0.8239 - distillation_loss: 7.0342e-04 - val_rmse: 0.9141 - val_correlation: 0.1407 - val_student_loss: 0.8980\n",
      "Epoch 12/140\n",
      "2046/2046 [==============================] - 28s 14ms/step - rmse: 0.9073 - correlation: 0.1636 - student_loss: 0.8235 - distillation_loss: 6.8341e-04 - val_rmse: 0.9141 - val_correlation: 0.1406 - val_student_loss: 0.8965\n",
      "Epoch 13/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9072 - correlation: 0.1644 - student_loss: 0.8233 - distillation_loss: 6.8824e-04 - val_rmse: 0.9142 - val_correlation: 0.1400 - val_student_loss: 0.8980\n",
      "Epoch 14/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9072 - correlation: 0.1649 - student_loss: 0.8232 - distillation_loss: 6.7738e-04 - val_rmse: 0.9144 - val_correlation: 0.1382 - val_student_loss: 0.8996\n",
      "Epoch 15/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9070 - correlation: 0.1658 - student_loss: 0.8230 - distillation_loss: 6.7971e-04 - val_rmse: 0.9140 - val_correlation: 0.1408 - val_student_loss: 0.8979\n",
      "Epoch 16/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9070 - correlation: 0.1664 - student_loss: 0.8228 - distillation_loss: 6.7553e-04 - val_rmse: 0.9141 - val_correlation: 0.1410 - val_student_loss: 0.8969\n",
      "Epoch 17/140\n",
      "2046/2046 [==============================] - 23s 11ms/step - rmse: 0.9069 - correlation: 0.1671 - student_loss: 0.8227 - distillation_loss: 6.1022e-04 - val_rmse: 0.9141 - val_correlation: 0.1424 - val_student_loss: 0.8984\n",
      "Epoch 18/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9068 - correlation: 0.1678 - student_loss: 0.8225 - distillation_loss: 5.9707e-04 - val_rmse: 0.9142 - val_correlation: 0.1417 - val_student_loss: 0.8984\n",
      "Epoch 19/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9067 - correlation: 0.1686 - student_loss: 0.8223 - distillation_loss: 5.9043e-04 - val_rmse: 0.9142 - val_correlation: 0.1413 - val_student_loss: 0.8980\n",
      "Epoch 20/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9066 - correlation: 0.1690 - student_loss: 0.8222 - distillation_loss: 5.8500e-04 - val_rmse: 0.9143 - val_correlation: 0.1404 - val_student_loss: 0.8991\n",
      "Epoch 21/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9065 - correlation: 0.1696 - student_loss: 0.8220 - distillation_loss: 5.8946e-04 - val_rmse: 0.9141 - val_correlation: 0.1414 - val_student_loss: 0.8995\n",
      "Epoch 22/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1700 - student_loss: 0.8219 - distillation_loss: 5.8553e-04 - val_rmse: 0.9142 - val_correlation: 0.1414 - val_student_loss: 0.8986\n",
      "Epoch 23/140\n",
      "2046/2046 [==============================] - 26s 13ms/step - rmse: 0.9064 - correlation: 0.1703 - student_loss: 0.8219 - distillation_loss: 5.8326e-04 - val_rmse: 0.9142 - val_correlation: 0.1405 - val_student_loss: 0.9000\n",
      "Epoch 24/140\n",
      "2046/2046 [==============================] - 25s 12ms/step - rmse: 0.9063 - correlation: 0.1708 - student_loss: 0.8217 - distillation_loss: 5.8409e-04 - val_rmse: 0.9141 - val_correlation: 0.1420 - val_student_loss: 0.8991\n",
      "Epoch 25/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9063 - correlation: 0.1708 - student_loss: 0.8217 - distillation_loss: 5.5341e-04 - val_rmse: 0.9141 - val_correlation: 0.1422 - val_student_loss: 0.8999\n",
      "Epoch 26/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9062 - correlation: 0.1718 - student_loss: 0.8214 - distillation_loss: 5.5080e-04 - val_rmse: 0.9141 - val_correlation: 0.1419 - val_student_loss: 0.8999\n",
      "Epoch 27/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9061 - correlation: 0.1722 - student_loss: 0.8213 - distillation_loss: 5.5098e-04 - val_rmse: 0.9141 - val_correlation: 0.1417 - val_student_loss: 0.9002\n",
      "Epoch 28/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9061 - correlation: 0.1723 - student_loss: 0.8213 - distillation_loss: 5.4457e-04 - val_rmse: 0.9140 - val_correlation: 0.1418 - val_student_loss: 0.9003\n",
      "Epoch 29/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9061 - correlation: 0.1724 - student_loss: 0.8213 - distillation_loss: 5.4492e-04 - val_rmse: 0.9140 - val_correlation: 0.1425 - val_student_loss: 0.8996\n",
      "Epoch 30/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9061 - correlation: 0.1727 - student_loss: 0.8212 - distillation_loss: 5.4372e-04 - val_rmse: 0.9140 - val_correlation: 0.1423 - val_student_loss: 0.8999\n",
      "Epoch 31/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9060 - correlation: 0.1730 - student_loss: 0.8211 - distillation_loss: 5.4269e-04 - val_rmse: 0.9140 - val_correlation: 0.1423 - val_student_loss: 0.8995\n",
      "Epoch 32/140\n",
      "2046/2046 [==============================] - 27s 13ms/step - rmse: 0.9060 - correlation: 0.1733 - student_loss: 0.8210 - distillation_loss: 5.4251e-04 - val_rmse: 0.9139 - val_correlation: 0.1443 - val_student_loss: 0.8988\n",
      "Epoch 33/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9060 - correlation: 0.1733 - student_loss: 0.8211 - distillation_loss: 5.2879e-04 - val_rmse: 0.9139 - val_correlation: 0.1429 - val_student_loss: 0.9003\n",
      "Epoch 34/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9059 - correlation: 0.1736 - student_loss: 0.8210 - distillation_loss: 5.2636e-04 - val_rmse: 0.9138 - val_correlation: 0.1436 - val_student_loss: 0.9002\n",
      "Epoch 35/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9059 - correlation: 0.1737 - student_loss: 0.8210 - distillation_loss: 5.2276e-04 - val_rmse: 0.9138 - val_correlation: 0.1439 - val_student_loss: 0.8998\n",
      "Epoch 36/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9059 - correlation: 0.1740 - student_loss: 0.8209 - distillation_loss: 5.2414e-04 - val_rmse: 0.9138 - val_correlation: 0.1438 - val_student_loss: 0.8999\n",
      "Epoch 37/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9058 - correlation: 0.1742 - student_loss: 0.8208 - distillation_loss: 5.2080e-04 - val_rmse: 0.9138 - val_correlation: 0.1433 - val_student_loss: 0.9001\n",
      "Epoch 38/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9059 - correlation: 0.1741 - student_loss: 0.8208 - distillation_loss: 5.2503e-04 - val_rmse: 0.9138 - val_correlation: 0.1441 - val_student_loss: 0.8999\n",
      "Epoch 39/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9058 - correlation: 0.1745 - student_loss: 0.8207 - distillation_loss: 5.2356e-04 - val_rmse: 0.9138 - val_correlation: 0.1438 - val_student_loss: 0.8996\n",
      "Epoch 40/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9058 - correlation: 0.1746 - student_loss: 0.8207 - distillation_loss: 5.2573e-04 - val_rmse: 0.9137 - val_correlation: 0.1442 - val_student_loss: 0.8996\n",
      "Epoch 41/140\n",
      "2046/2046 [==============================] - 29s 14ms/step - rmse: 0.9058 - correlation: 0.1743 - student_loss: 0.8208 - distillation_loss: 5.1185e-04 - val_rmse: 0.9138 - val_correlation: 0.1443 - val_student_loss: 0.8999\n",
      "Epoch 42/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9058 - correlation: 0.1746 - student_loss: 0.8207 - distillation_loss: 5.1203e-04 - val_rmse: 0.9137 - val_correlation: 0.1447 - val_student_loss: 0.8996\n",
      "Epoch 43/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9058 - correlation: 0.1748 - student_loss: 0.8207 - distillation_loss: 5.0982e-04 - val_rmse: 0.9137 - val_correlation: 0.1443 - val_student_loss: 0.8999\n",
      "Epoch 44/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9058 - correlation: 0.1748 - student_loss: 0.8207 - distillation_loss: 5.1030e-04 - val_rmse: 0.9137 - val_correlation: 0.1443 - val_student_loss: 0.8999\n",
      "Epoch 45/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1751 - student_loss: 0.8206 - distillation_loss: 5.1129e-04 - val_rmse: 0.9137 - val_correlation: 0.1447 - val_student_loss: 0.8997\n",
      "Epoch 46/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9058 - correlation: 0.1747 - student_loss: 0.8207 - distillation_loss: 5.1022e-04 - val_rmse: 0.9137 - val_correlation: 0.1447 - val_student_loss: 0.8998\n",
      "Epoch 47/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1751 - student_loss: 0.8206 - distillation_loss: 5.1103e-04 - val_rmse: 0.9137 - val_correlation: 0.1446 - val_student_loss: 0.9000\n",
      "Epoch 48/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1750 - student_loss: 0.8206 - distillation_loss: 5.1064e-04 - val_rmse: 0.9137 - val_correlation: 0.1445 - val_student_loss: 0.8998\n",
      "Epoch 49/140\n",
      "2046/2046 [==============================] - 28s 14ms/step - rmse: 0.9058 - correlation: 0.1749 - student_loss: 0.8207 - distillation_loss: 5.0539e-04 - val_rmse: 0.9137 - val_correlation: 0.1450 - val_student_loss: 0.8999\n",
      "Epoch 50/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9057 - correlation: 0.1751 - student_loss: 0.8206 - distillation_loss: 5.0381e-04 - val_rmse: 0.9137 - val_correlation: 0.1449 - val_student_loss: 0.8998\n",
      "Epoch 51/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1751 - student_loss: 0.8206 - distillation_loss: 5.0467e-04 - val_rmse: 0.9137 - val_correlation: 0.1449 - val_student_loss: 0.8998\n",
      "Epoch 52/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1753 - student_loss: 0.8206 - distillation_loss: 5.0449e-04 - val_rmse: 0.9137 - val_correlation: 0.1448 - val_student_loss: 0.9001\n",
      "Epoch 53/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1751 - student_loss: 0.8206 - distillation_loss: 5.0389e-04 - val_rmse: 0.9137 - val_correlation: 0.1447 - val_student_loss: 0.9001\n",
      "Epoch 54/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1753 - student_loss: 0.8206 - distillation_loss: 5.0196e-04 - val_rmse: 0.9137 - val_correlation: 0.1450 - val_student_loss: 0.8998\n",
      "Epoch 55/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1753 - student_loss: 0.8206 - distillation_loss: 5.0177e-04 - val_rmse: 0.9136 - val_correlation: 0.1452 - val_student_loss: 0.8996\n",
      "Epoch 56/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1752 - student_loss: 0.8206 - distillation_loss: 5.0231e-04 - val_rmse: 0.9137 - val_correlation: 0.1451 - val_student_loss: 0.8996\n",
      "Epoch 57/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9058 - correlation: 0.1749 - student_loss: 0.8207 - distillation_loss: 4.9717e-04 - val_rmse: 0.9135 - val_correlation: 0.1459 - val_student_loss: 0.8995\n",
      "Epoch 58/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9057 - correlation: 0.1755 - student_loss: 0.8205 - distillation_loss: 5.0034e-04 - val_rmse: 0.9135 - val_correlation: 0.1457 - val_student_loss: 0.8997\n",
      "Epoch 59/140\n",
      "2046/2046 [==============================] - 27s 13ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8205 - distillation_loss: 4.9689e-04 - val_rmse: 0.9135 - val_correlation: 0.1459 - val_student_loss: 0.8996\n",
      "Epoch 60/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9057 - correlation: 0.1751 - student_loss: 0.8206 - distillation_loss: 4.9872e-04 - val_rmse: 0.9135 - val_correlation: 0.1460 - val_student_loss: 0.8995\n",
      "Epoch 61/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8205 - distillation_loss: 4.9932e-04 - val_rmse: 0.9135 - val_correlation: 0.1460 - val_student_loss: 0.8994\n",
      "Epoch 62/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1752 - student_loss: 0.8206 - distillation_loss: 5.0000e-04 - val_rmse: 0.9135 - val_correlation: 0.1460 - val_student_loss: 0.8994\n",
      "Epoch 63/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1755 - student_loss: 0.8205 - distillation_loss: 5.0135e-04 - val_rmse: 0.9135 - val_correlation: 0.1458 - val_student_loss: 0.8997\n",
      "Epoch 64/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1756 - student_loss: 0.8205 - distillation_loss: 5.0117e-04 - val_rmse: 0.9135 - val_correlation: 0.1459 - val_student_loss: 0.8997\n",
      "Epoch 65/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1753 - student_loss: 0.8206 - distillation_loss: 4.9485e-04 - val_rmse: 0.9135 - val_correlation: 0.1467 - val_student_loss: 0.8991\n",
      "Epoch 66/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1753 - student_loss: 0.8206 - distillation_loss: 4.9664e-04 - val_rmse: 0.9134 - val_correlation: 0.1467 - val_student_loss: 0.8990\n",
      "Epoch 67/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8205 - distillation_loss: 4.9742e-04 - val_rmse: 0.9134 - val_correlation: 0.1468 - val_student_loss: 0.8990\n",
      "Epoch 68/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8205 - distillation_loss: 4.9874e-04 - val_rmse: 0.9134 - val_correlation: 0.1469 - val_student_loss: 0.8990\n",
      "Epoch 69/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9056 - correlation: 0.1757 - student_loss: 0.8204 - distillation_loss: 4.9697e-04 - val_rmse: 0.9135 - val_correlation: 0.1467 - val_student_loss: 0.8991\n",
      "Epoch 70/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8205 - distillation_loss: 4.9789e-04 - val_rmse: 0.9134 - val_correlation: 0.1468 - val_student_loss: 0.8990\n",
      "Epoch 71/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8205 - distillation_loss: 4.9912e-04 - val_rmse: 0.9134 - val_correlation: 0.1468 - val_student_loss: 0.8991\n",
      "Epoch 72/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1752 - student_loss: 0.8206 - distillation_loss: 4.9345e-04 - val_rmse: 0.9134 - val_correlation: 0.1469 - val_student_loss: 0.8990\n",
      "Epoch 73/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1752 - student_loss: 0.8206 - distillation_loss: 4.9587e-04 - val_rmse: 0.9134 - val_correlation: 0.1472 - val_student_loss: 0.8988\n",
      "Epoch 74/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8205 - distillation_loss: 4.9783e-04 - val_rmse: 0.9134 - val_correlation: 0.1473 - val_student_loss: 0.8988\n",
      "Epoch 75/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1753 - student_loss: 0.8206 - distillation_loss: 4.9711e-04 - val_rmse: 0.9134 - val_correlation: 0.1472 - val_student_loss: 0.8988\n",
      "Epoch 76/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1755 - student_loss: 0.8205 - distillation_loss: 4.9592e-04 - val_rmse: 0.9134 - val_correlation: 0.1473 - val_student_loss: 0.8988\n",
      "Epoch 77/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1757 - student_loss: 0.8205 - distillation_loss: 4.9369e-04 - val_rmse: 0.9134 - val_correlation: 0.1472 - val_student_loss: 0.8989\n",
      "Epoch 78/140\n",
      "2046/2046 [==============================] - 27s 13ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9615e-04 - val_rmse: 0.9134 - val_correlation: 0.1472 - val_student_loss: 0.8989\n",
      "Epoch 79/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1756 - student_loss: 0.8205 - distillation_loss: 4.9652e-04 - val_rmse: 0.9134 - val_correlation: 0.1472 - val_student_loss: 0.8989\n",
      "Epoch 80/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1755 - student_loss: 0.8205 - distillation_loss: 4.9492e-04 - val_rmse: 0.9134 - val_correlation: 0.1473 - val_student_loss: 0.8988\n",
      "Epoch 81/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1753 - student_loss: 0.8206 - distillation_loss: 4.9443e-04 - val_rmse: 0.9133 - val_correlation: 0.1477 - val_student_loss: 0.8986\n",
      "Epoch 82/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9521e-04 - val_rmse: 0.9133 - val_correlation: 0.1478 - val_student_loss: 0.8986\n",
      "Epoch 83/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1752 - student_loss: 0.8206 - distillation_loss: 4.9405e-04 - val_rmse: 0.9133 - val_correlation: 0.1478 - val_student_loss: 0.8985\n",
      "Epoch 84/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9557e-04 - val_rmse: 0.9133 - val_correlation: 0.1479 - val_student_loss: 0.8985\n",
      "Epoch 85/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1757 - student_loss: 0.8205 - distillation_loss: 4.9701e-04 - val_rmse: 0.9133 - val_correlation: 0.1477 - val_student_loss: 0.8986\n",
      "Epoch 86/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9290e-04 - val_rmse: 0.9133 - val_correlation: 0.1478 - val_student_loss: 0.8985\n",
      "Epoch 87/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1753 - student_loss: 0.8206 - distillation_loss: 4.9507e-04 - val_rmse: 0.9133 - val_correlation: 0.1478 - val_student_loss: 0.8985\n",
      "Epoch 88/140\n",
      "2046/2046 [==============================] - 28s 14ms/step - rmse: 0.9057 - correlation: 0.1755 - student_loss: 0.8205 - distillation_loss: 4.9632e-04 - val_rmse: 0.9133 - val_correlation: 0.1479 - val_student_loss: 0.8985\n",
      "Epoch 89/140\n",
      "2046/2046 [==============================] - 26s 13ms/step - rmse: 0.9057 - correlation: 0.1753 - student_loss: 0.8206 - distillation_loss: 4.9208e-04 - val_rmse: 0.9133 - val_correlation: 0.1482 - val_student_loss: 0.8984\n",
      "Epoch 90/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9521e-04 - val_rmse: 0.9133 - val_correlation: 0.1482 - val_student_loss: 0.8983\n",
      "Epoch 91/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1756 - student_loss: 0.8205 - distillation_loss: 4.9535e-04 - val_rmse: 0.9133 - val_correlation: 0.1482 - val_student_loss: 0.8984\n",
      "Epoch 92/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9433e-04 - val_rmse: 0.9133 - val_correlation: 0.1482 - val_student_loss: 0.8984\n",
      "Epoch 93/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9249e-04 - val_rmse: 0.9133 - val_correlation: 0.1482 - val_student_loss: 0.8983\n",
      "Epoch 94/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1756 - student_loss: 0.8205 - distillation_loss: 4.9792e-04 - val_rmse: 0.9133 - val_correlation: 0.1483 - val_student_loss: 0.8983\n",
      "Epoch 95/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1753 - student_loss: 0.8206 - distillation_loss: 4.9450e-04 - val_rmse: 0.9133 - val_correlation: 0.1482 - val_student_loss: 0.8984\n",
      "Epoch 96/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1753 - student_loss: 0.8206 - distillation_loss: 4.9623e-04 - val_rmse: 0.9133 - val_correlation: 0.1483 - val_student_loss: 0.8983\n",
      "Epoch 97/140\n",
      "2046/2046 [==============================] - 29s 14ms/step - rmse: 0.9057 - correlation: 0.1753 - student_loss: 0.8206 - distillation_loss: 4.9336e-04 - val_rmse: 0.9133 - val_correlation: 0.1485 - val_student_loss: 0.8982\n",
      "Epoch 98/140\n",
      "2046/2046 [==============================] - 25s 12ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9187e-04 - val_rmse: 0.9133 - val_correlation: 0.1485 - val_student_loss: 0.8982\n",
      "Epoch 99/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1755 - student_loss: 0.8205 - distillation_loss: 4.9443e-04 - val_rmse: 0.9133 - val_correlation: 0.1485 - val_student_loss: 0.8982\n",
      "Epoch 100/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9057 - correlation: 0.1753 - student_loss: 0.8206 - distillation_loss: 4.9777e-04 - val_rmse: 0.9133 - val_correlation: 0.1485 - val_student_loss: 0.8982\n",
      "Epoch 101/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9384e-04 - val_rmse: 0.9133 - val_correlation: 0.1485 - val_student_loss: 0.8982\n",
      "Epoch 102/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9452e-04 - val_rmse: 0.9133 - val_correlation: 0.1485 - val_student_loss: 0.8982\n",
      "Epoch 103/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9057 - correlation: 0.1755 - student_loss: 0.8205 - distillation_loss: 4.9562e-04 - val_rmse: 0.9133 - val_correlation: 0.1485 - val_student_loss: 0.8982\n",
      "Epoch 104/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9652e-04 - val_rmse: 0.9133 - val_correlation: 0.1485 - val_student_loss: 0.8982\n",
      "Epoch 105/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1753 - student_loss: 0.8206 - distillation_loss: 4.9585e-04 - val_rmse: 0.9133 - val_correlation: 0.1486 - val_student_loss: 0.8982\n",
      "Epoch 106/140\n",
      "2046/2046 [==============================] - 29s 14ms/step - rmse: 0.9057 - correlation: 0.1753 - student_loss: 0.8206 - distillation_loss: 4.9354e-04 - val_rmse: 0.9133 - val_correlation: 0.1486 - val_student_loss: 0.8981\n",
      "Epoch 107/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1755 - student_loss: 0.8205 - distillation_loss: 4.9360e-04 - val_rmse: 0.9133 - val_correlation: 0.1486 - val_student_loss: 0.8981\n",
      "Epoch 108/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1753 - student_loss: 0.8206 - distillation_loss: 4.9621e-04 - val_rmse: 0.9133 - val_correlation: 0.1486 - val_student_loss: 0.8981\n",
      "Epoch 109/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8205 - distillation_loss: 4.9807e-04 - val_rmse: 0.9133 - val_correlation: 0.1486 - val_student_loss: 0.8981\n",
      "Epoch 110/140\n",
      "2046/2046 [==============================] - 21s 11ms/step - rmse: 0.9057 - correlation: 0.1755 - student_loss: 0.8205 - distillation_loss: 4.9776e-04 - val_rmse: 0.9132 - val_correlation: 0.1486 - val_student_loss: 0.8981\n",
      "Epoch 111/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1755 - student_loss: 0.8205 - distillation_loss: 4.9641e-04 - val_rmse: 0.9133 - val_correlation: 0.1486 - val_student_loss: 0.8981\n",
      "Epoch 112/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1755 - student_loss: 0.8205 - distillation_loss: 4.9692e-04 - val_rmse: 0.9133 - val_correlation: 0.1486 - val_student_loss: 0.8981\n",
      "Epoch 113/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1752 - student_loss: 0.8206 - distillation_loss: 4.9401e-04 - val_rmse: 0.9133 - val_correlation: 0.1486 - val_student_loss: 0.8981\n",
      "Epoch 114/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1755 - student_loss: 0.8205 - distillation_loss: 4.9580e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 115/140\n",
      "2046/2046 [==============================] - 26s 13ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9556e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 116/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1755 - student_loss: 0.8205 - distillation_loss: 4.9397e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 117/140\n",
      "2046/2046 [==============================] - 22s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9524e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 118/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1755 - student_loss: 0.8205 - distillation_loss: 4.9573e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 119/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1755 - student_loss: 0.8205 - distillation_loss: 4.9156e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 120/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9417e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 121/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9057 - correlation: 0.1753 - student_loss: 0.8206 - distillation_loss: 4.9353e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 122/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1753 - student_loss: 0.8206 - distillation_loss: 4.9973e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 123/140\n",
      "2046/2046 [==============================] - 26s 12ms/step - rmse: 0.9057 - correlation: 0.1755 - student_loss: 0.8206 - distillation_loss: 4.9510e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 124/140\n",
      "2046/2046 [==============================] - 30s 14ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9706e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 125/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8205 - distillation_loss: 4.9479e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 126/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9057 - correlation: 0.1755 - student_loss: 0.8205 - distillation_loss: 4.9496e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 127/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9562e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 128/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9382e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 129/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1756 - student_loss: 0.8205 - distillation_loss: 4.9372e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 130/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9353e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 131/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9617e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 132/140\n",
      "2046/2046 [==============================] - 28s 14ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9548e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 133/140\n",
      "2046/2046 [==============================] - 29s 14ms/step - rmse: 0.9057 - correlation: 0.1755 - student_loss: 0.8205 - distillation_loss: 4.9676e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 134/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9386e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 135/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9452e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 136/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9057 - correlation: 0.1755 - student_loss: 0.8205 - distillation_loss: 4.9850e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 137/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1753 - student_loss: 0.8206 - distillation_loss: 4.9483e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 138/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9579e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 139/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9057 - correlation: 0.1754 - student_loss: 0.8206 - distillation_loss: 4.9523e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Epoch 140/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9057 - correlation: 0.1755 - student_loss: 0.8205 - distillation_loss: 4.9485e-04 - val_rmse: 0.9132 - val_correlation: 0.1487 - val_student_loss: 0.8981\n",
      "Pearson: 0.14976709325092308\n",
      "Epoch 1/140\n",
      "2046/2046 [==============================] - 44s 20ms/step - rmse: 0.9109 - correlation: 0.1425 - student_loss: 0.8297 - distillation_loss: 0.0022 - val_rmse: 0.9156 - val_correlation: 0.1310 - val_student_loss: 0.7383\n",
      "Epoch 2/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9099 - correlation: 0.1494 - student_loss: 0.8279 - distillation_loss: 0.0013 - val_rmse: 0.9160 - val_correlation: 0.1276 - val_student_loss: 0.7445\n",
      "Epoch 3/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9096 - correlation: 0.1518 - student_loss: 0.8274 - distillation_loss: 0.0011 - val_rmse: 0.9153 - val_correlation: 0.1331 - val_student_loss: 0.7384\n",
      "Epoch 4/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9094 - correlation: 0.1533 - student_loss: 0.8270 - distillation_loss: 0.0010 - val_rmse: 0.9152 - val_correlation: 0.1331 - val_student_loss: 0.7390\n",
      "Epoch 5/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9091 - correlation: 0.1551 - student_loss: 0.8265 - distillation_loss: 9.9281e-04 - val_rmse: 0.9150 - val_correlation: 0.1352 - val_student_loss: 0.7406\n",
      "Epoch 6/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9090 - correlation: 0.1563 - student_loss: 0.8262 - distillation_loss: 9.5656e-04 - val_rmse: 0.9144 - val_correlation: 0.1392 - val_student_loss: 0.7385\n",
      "Epoch 7/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9088 - correlation: 0.1573 - student_loss: 0.8259 - distillation_loss: 9.4551e-04 - val_rmse: 0.9149 - val_correlation: 0.1359 - val_student_loss: 0.7386\n",
      "Epoch 8/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9087 - correlation: 0.1582 - student_loss: 0.8257 - distillation_loss: 9.0569e-04 - val_rmse: 0.9144 - val_correlation: 0.1417 - val_student_loss: 0.7394\n",
      "Epoch 9/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9086 - correlation: 0.1589 - student_loss: 0.8256 - distillation_loss: 7.6120e-04 - val_rmse: 0.9147 - val_correlation: 0.1374 - val_student_loss: 0.7437\n",
      "Epoch 10/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9084 - correlation: 0.1608 - student_loss: 0.8251 - distillation_loss: 7.2762e-04 - val_rmse: 0.9146 - val_correlation: 0.1375 - val_student_loss: 0.7429\n",
      "Epoch 11/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9082 - correlation: 0.1616 - student_loss: 0.8249 - distillation_loss: 7.1609e-04 - val_rmse: 0.9146 - val_correlation: 0.1377 - val_student_loss: 0.7428\n",
      "Epoch 12/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9081 - correlation: 0.1623 - student_loss: 0.8247 - distillation_loss: 6.9791e-04 - val_rmse: 0.9145 - val_correlation: 0.1386 - val_student_loss: 0.7416\n",
      "Epoch 13/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9080 - correlation: 0.1631 - student_loss: 0.8246 - distillation_loss: 6.9620e-04 - val_rmse: 0.9146 - val_correlation: 0.1384 - val_student_loss: 0.7452\n",
      "Epoch 14/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9079 - correlation: 0.1640 - student_loss: 0.8243 - distillation_loss: 6.8575e-04 - val_rmse: 0.9145 - val_correlation: 0.1387 - val_student_loss: 0.7434\n",
      "Epoch 15/140\n",
      "2046/2046 [==============================] - 28s 14ms/step - rmse: 0.9078 - correlation: 0.1646 - student_loss: 0.8242 - distillation_loss: 6.7303e-04 - val_rmse: 0.9145 - val_correlation: 0.1390 - val_student_loss: 0.7429\n",
      "Epoch 16/140\n",
      "2046/2046 [==============================] - 31s 15ms/step - rmse: 0.9077 - correlation: 0.1652 - student_loss: 0.8239 - distillation_loss: 6.7088e-04 - val_rmse: 0.9144 - val_correlation: 0.1399 - val_student_loss: 0.7432\n",
      "Epoch 17/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9076 - correlation: 0.1659 - student_loss: 0.8238 - distillation_loss: 6.1750e-04 - val_rmse: 0.9147 - val_correlation: 0.1383 - val_student_loss: 0.7414\n",
      "Epoch 18/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9075 - correlation: 0.1671 - student_loss: 0.8235 - distillation_loss: 5.9950e-04 - val_rmse: 0.9145 - val_correlation: 0.1395 - val_student_loss: 0.7424\n",
      "Epoch 19/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9074 - correlation: 0.1677 - student_loss: 0.8233 - distillation_loss: 5.9848e-04 - val_rmse: 0.9148 - val_correlation: 0.1368 - val_student_loss: 0.7436\n",
      "Epoch 20/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9073 - correlation: 0.1681 - student_loss: 0.8232 - distillation_loss: 5.8922e-04 - val_rmse: 0.9144 - val_correlation: 0.1393 - val_student_loss: 0.7427\n",
      "Epoch 21/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9073 - correlation: 0.1684 - student_loss: 0.8232 - distillation_loss: 5.9156e-04 - val_rmse: 0.9146 - val_correlation: 0.1377 - val_student_loss: 0.7435\n",
      "Epoch 22/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9072 - correlation: 0.1692 - student_loss: 0.8229 - distillation_loss: 5.8817e-04 - val_rmse: 0.9145 - val_correlation: 0.1393 - val_student_loss: 0.7413\n",
      "Epoch 23/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9071 - correlation: 0.1693 - student_loss: 0.8229 - distillation_loss: 5.8657e-04 - val_rmse: 0.9145 - val_correlation: 0.1385 - val_student_loss: 0.7417\n",
      "Epoch 24/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9070 - correlation: 0.1703 - student_loss: 0.8227 - distillation_loss: 5.8759e-04 - val_rmse: 0.9144 - val_correlation: 0.1395 - val_student_loss: 0.7413\n",
      "Epoch 25/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9070 - correlation: 0.1703 - student_loss: 0.8227 - distillation_loss: 5.5106e-04 - val_rmse: 0.9144 - val_correlation: 0.1400 - val_student_loss: 0.7417\n",
      "Epoch 26/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9069 - correlation: 0.1707 - student_loss: 0.8225 - distillation_loss: 5.4710e-04 - val_rmse: 0.9143 - val_correlation: 0.1408 - val_student_loss: 0.7407\n",
      "Epoch 27/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9069 - correlation: 0.1707 - student_loss: 0.8225 - distillation_loss: 5.4749e-04 - val_rmse: 0.9144 - val_correlation: 0.1400 - val_student_loss: 0.7414\n",
      "Epoch 28/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9069 - correlation: 0.1711 - student_loss: 0.8224 - distillation_loss: 5.4420e-04 - val_rmse: 0.9144 - val_correlation: 0.1395 - val_student_loss: 0.7424\n",
      "Epoch 29/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9068 - correlation: 0.1718 - student_loss: 0.8223 - distillation_loss: 5.4424e-04 - val_rmse: 0.9143 - val_correlation: 0.1406 - val_student_loss: 0.7419\n",
      "Epoch 30/140\n",
      "2046/2046 [==============================] - 25s 12ms/step - rmse: 0.9068 - correlation: 0.1720 - student_loss: 0.8222 - distillation_loss: 5.4332e-04 - val_rmse: 0.9143 - val_correlation: 0.1403 - val_student_loss: 0.7422\n",
      "Epoch 31/140\n",
      "2046/2046 [==============================] - 26s 13ms/step - rmse: 0.9068 - correlation: 0.1720 - student_loss: 0.8222 - distillation_loss: 5.4321e-04 - val_rmse: 0.9143 - val_correlation: 0.1405 - val_student_loss: 0.7413\n",
      "Epoch 32/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9067 - correlation: 0.1723 - student_loss: 0.8221 - distillation_loss: 5.4166e-04 - val_rmse: 0.9144 - val_correlation: 0.1399 - val_student_loss: 0.7431\n",
      "Epoch 33/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9067 - correlation: 0.1724 - student_loss: 0.8221 - distillation_loss: 5.2732e-04 - val_rmse: 0.9142 - val_correlation: 0.1413 - val_student_loss: 0.7420\n",
      "Epoch 34/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9066 - correlation: 0.1727 - student_loss: 0.8220 - distillation_loss: 5.2516e-04 - val_rmse: 0.9142 - val_correlation: 0.1416 - val_student_loss: 0.7417\n",
      "Epoch 35/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9067 - correlation: 0.1726 - student_loss: 0.8220 - distillation_loss: 5.2175e-04 - val_rmse: 0.9141 - val_correlation: 0.1419 - val_student_loss: 0.7417\n",
      "Epoch 36/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9066 - correlation: 0.1728 - student_loss: 0.8220 - distillation_loss: 5.1938e-04 - val_rmse: 0.9142 - val_correlation: 0.1415 - val_student_loss: 0.7420\n",
      "Epoch 37/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9066 - correlation: 0.1731 - student_loss: 0.8219 - distillation_loss: 5.2169e-04 - val_rmse: 0.9142 - val_correlation: 0.1418 - val_student_loss: 0.7419\n",
      "Epoch 38/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9066 - correlation: 0.1734 - student_loss: 0.8218 - distillation_loss: 5.2192e-04 - val_rmse: 0.9141 - val_correlation: 0.1423 - val_student_loss: 0.7413\n",
      "Epoch 39/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9066 - correlation: 0.1733 - student_loss: 0.8218 - distillation_loss: 5.1816e-04 - val_rmse: 0.9140 - val_correlation: 0.1426 - val_student_loss: 0.7415\n",
      "Epoch 40/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9065 - correlation: 0.1736 - student_loss: 0.8218 - distillation_loss: 5.2012e-04 - val_rmse: 0.9141 - val_correlation: 0.1424 - val_student_loss: 0.7413\n",
      "Epoch 41/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9065 - correlation: 0.1734 - student_loss: 0.8218 - distillation_loss: 5.1128e-04 - val_rmse: 0.9141 - val_correlation: 0.1427 - val_student_loss: 0.7412\n",
      "Epoch 42/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9065 - correlation: 0.1736 - student_loss: 0.8218 - distillation_loss: 5.0761e-04 - val_rmse: 0.9141 - val_correlation: 0.1425 - val_student_loss: 0.7415\n",
      "Epoch 43/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9065 - correlation: 0.1738 - student_loss: 0.8217 - distillation_loss: 5.0889e-04 - val_rmse: 0.9141 - val_correlation: 0.1424 - val_student_loss: 0.7414\n",
      "Epoch 44/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9065 - correlation: 0.1739 - student_loss: 0.8217 - distillation_loss: 5.0944e-04 - val_rmse: 0.9140 - val_correlation: 0.1427 - val_student_loss: 0.7413\n",
      "Epoch 45/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9065 - correlation: 0.1740 - student_loss: 0.8217 - distillation_loss: 5.1041e-04 - val_rmse: 0.9141 - val_correlation: 0.1426 - val_student_loss: 0.7414\n",
      "Epoch 46/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1741 - student_loss: 0.8216 - distillation_loss: 5.1111e-04 - val_rmse: 0.9141 - val_correlation: 0.1426 - val_student_loss: 0.7410\n",
      "Epoch 47/140\n",
      "2046/2046 [==============================] - 26s 13ms/step - rmse: 0.9064 - correlation: 0.1743 - student_loss: 0.8216 - distillation_loss: 5.0802e-04 - val_rmse: 0.9140 - val_correlation: 0.1428 - val_student_loss: 0.7413\n",
      "Epoch 48/140\n",
      "2046/2046 [==============================] - 26s 13ms/step - rmse: 0.9064 - correlation: 0.1741 - student_loss: 0.8216 - distillation_loss: 5.0773e-04 - val_rmse: 0.9140 - val_correlation: 0.1431 - val_student_loss: 0.7409\n",
      "Epoch 49/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1742 - student_loss: 0.8216 - distillation_loss: 5.0339e-04 - val_rmse: 0.9140 - val_correlation: 0.1431 - val_student_loss: 0.7412\n",
      "Epoch 50/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 5.0338e-04 - val_rmse: 0.9140 - val_correlation: 0.1434 - val_student_loss: 0.7413\n",
      "Epoch 51/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1743 - student_loss: 0.8216 - distillation_loss: 4.9933e-04 - val_rmse: 0.9140 - val_correlation: 0.1430 - val_student_loss: 0.7414\n",
      "Epoch 52/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1744 - student_loss: 0.8216 - distillation_loss: 5.0594e-04 - val_rmse: 0.9140 - val_correlation: 0.1431 - val_student_loss: 0.7412\n",
      "Epoch 53/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1743 - student_loss: 0.8216 - distillation_loss: 5.0013e-04 - val_rmse: 0.9140 - val_correlation: 0.1433 - val_student_loss: 0.7413\n",
      "Epoch 54/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1744 - student_loss: 0.8216 - distillation_loss: 5.0167e-04 - val_rmse: 0.9140 - val_correlation: 0.1434 - val_student_loss: 0.7412\n",
      "Epoch 55/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1743 - student_loss: 0.8216 - distillation_loss: 5.0247e-04 - val_rmse: 0.9140 - val_correlation: 0.1432 - val_student_loss: 0.7412\n",
      "Epoch 56/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1743 - student_loss: 0.8216 - distillation_loss: 5.0466e-04 - val_rmse: 0.9139 - val_correlation: 0.1435 - val_student_loss: 0.7411\n",
      "Epoch 57/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1742 - student_loss: 0.8216 - distillation_loss: 4.9920e-04 - val_rmse: 0.9138 - val_correlation: 0.1444 - val_student_loss: 0.7409\n",
      "Epoch 58/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1746 - student_loss: 0.8215 - distillation_loss: 5.0110e-04 - val_rmse: 0.9138 - val_correlation: 0.1443 - val_student_loss: 0.7410\n",
      "Epoch 59/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1744 - student_loss: 0.8216 - distillation_loss: 5.0059e-04 - val_rmse: 0.9138 - val_correlation: 0.1444 - val_student_loss: 0.7411\n",
      "Epoch 60/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1746 - student_loss: 0.8215 - distillation_loss: 4.9842e-04 - val_rmse: 0.9138 - val_correlation: 0.1444 - val_student_loss: 0.7411\n",
      "Epoch 61/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 4.9706e-04 - val_rmse: 0.9138 - val_correlation: 0.1443 - val_student_loss: 0.7410\n",
      "Epoch 62/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1744 - student_loss: 0.8216 - distillation_loss: 4.9777e-04 - val_rmse: 0.9138 - val_correlation: 0.1445 - val_student_loss: 0.7410\n",
      "Epoch 63/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8215 - distillation_loss: 4.9861e-04 - val_rmse: 0.9138 - val_correlation: 0.1448 - val_student_loss: 0.7408\n",
      "Epoch 64/140\n",
      "2046/2046 [==============================] - 27s 13ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 4.9952e-04 - val_rmse: 0.9138 - val_correlation: 0.1445 - val_student_loss: 0.7411\n",
      "Epoch 65/140\n",
      "2046/2046 [==============================] - 26s 13ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 4.9824e-04 - val_rmse: 0.9138 - val_correlation: 0.1449 - val_student_loss: 0.7410\n",
      "Epoch 66/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1747 - student_loss: 0.8215 - distillation_loss: 4.9816e-04 - val_rmse: 0.9138 - val_correlation: 0.1450 - val_student_loss: 0.7409\n",
      "Epoch 67/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1746 - student_loss: 0.8215 - distillation_loss: 4.9921e-04 - val_rmse: 0.9137 - val_correlation: 0.1451 - val_student_loss: 0.7410\n",
      "Epoch 68/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1746 - student_loss: 0.8215 - distillation_loss: 4.9647e-04 - val_rmse: 0.9138 - val_correlation: 0.1450 - val_student_loss: 0.7411\n",
      "Epoch 69/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1746 - student_loss: 0.8215 - distillation_loss: 4.9514e-04 - val_rmse: 0.9138 - val_correlation: 0.1450 - val_student_loss: 0.7410\n",
      "Epoch 70/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1746 - student_loss: 0.8215 - distillation_loss: 4.9899e-04 - val_rmse: 0.9137 - val_correlation: 0.1451 - val_student_loss: 0.7409\n",
      "Epoch 71/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1746 - student_loss: 0.8215 - distillation_loss: 4.9578e-04 - val_rmse: 0.9137 - val_correlation: 0.1450 - val_student_loss: 0.7410\n",
      "Epoch 72/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1744 - student_loss: 0.8216 - distillation_loss: 4.9547e-04 - val_rmse: 0.9137 - val_correlation: 0.1451 - val_student_loss: 0.7409\n",
      "Epoch 73/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8215 - distillation_loss: 4.9770e-04 - val_rmse: 0.9137 - val_correlation: 0.1455 - val_student_loss: 0.7409\n",
      "Epoch 74/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1744 - student_loss: 0.8216 - distillation_loss: 4.9361e-04 - val_rmse: 0.9137 - val_correlation: 0.1456 - val_student_loss: 0.7409\n",
      "Epoch 75/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 4.9599e-04 - val_rmse: 0.9137 - val_correlation: 0.1456 - val_student_loss: 0.7409\n",
      "Epoch 76/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1747 - student_loss: 0.8215 - distillation_loss: 4.9554e-04 - val_rmse: 0.9137 - val_correlation: 0.1456 - val_student_loss: 0.7409\n",
      "Epoch 77/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 4.9718e-04 - val_rmse: 0.9137 - val_correlation: 0.1456 - val_student_loss: 0.7409\n",
      "Epoch 78/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8215 - distillation_loss: 4.9442e-04 - val_rmse: 0.9137 - val_correlation: 0.1457 - val_student_loss: 0.7409\n",
      "Epoch 79/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1748 - student_loss: 0.8215 - distillation_loss: 4.9714e-04 - val_rmse: 0.9137 - val_correlation: 0.1457 - val_student_loss: 0.7408\n",
      "Epoch 80/140\n",
      "2046/2046 [==============================] - 25s 12ms/step - rmse: 0.9064 - correlation: 0.1747 - student_loss: 0.8215 - distillation_loss: 4.9532e-04 - val_rmse: 0.9137 - val_correlation: 0.1458 - val_student_loss: 0.7408\n",
      "Epoch 81/140\n",
      "2046/2046 [==============================] - 28s 14ms/step - rmse: 0.9064 - correlation: 0.1744 - student_loss: 0.8216 - distillation_loss: 4.9679e-04 - val_rmse: 0.9136 - val_correlation: 0.1461 - val_student_loss: 0.7407\n",
      "Epoch 82/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1743 - student_loss: 0.8216 - distillation_loss: 4.9365e-04 - val_rmse: 0.9136 - val_correlation: 0.1459 - val_student_loss: 0.7408\n",
      "Epoch 83/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1746 - student_loss: 0.8215 - distillation_loss: 4.9320e-04 - val_rmse: 0.9136 - val_correlation: 0.1461 - val_student_loss: 0.7407\n",
      "Epoch 84/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 4.9570e-04 - val_rmse: 0.9136 - val_correlation: 0.1461 - val_student_loss: 0.7407\n",
      "Epoch 85/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8215 - distillation_loss: 4.9666e-04 - val_rmse: 0.9136 - val_correlation: 0.1461 - val_student_loss: 0.7408\n",
      "Epoch 86/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1743 - student_loss: 0.8216 - distillation_loss: 4.9684e-04 - val_rmse: 0.9136 - val_correlation: 0.1461 - val_student_loss: 0.7408\n",
      "Epoch 87/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1748 - student_loss: 0.8215 - distillation_loss: 4.9819e-04 - val_rmse: 0.9136 - val_correlation: 0.1461 - val_student_loss: 0.7408\n",
      "Epoch 88/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1744 - student_loss: 0.8216 - distillation_loss: 4.9585e-04 - val_rmse: 0.9136 - val_correlation: 0.1462 - val_student_loss: 0.7408\n",
      "Epoch 89/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1744 - student_loss: 0.8216 - distillation_loss: 4.9644e-04 - val_rmse: 0.9136 - val_correlation: 0.1465 - val_student_loss: 0.7406\n",
      "Epoch 90/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9064 - correlation: 0.1747 - student_loss: 0.8215 - distillation_loss: 5.0108e-04 - val_rmse: 0.9136 - val_correlation: 0.1465 - val_student_loss: 0.7406\n",
      "Epoch 91/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1746 - student_loss: 0.8215 - distillation_loss: 4.9704e-04 - val_rmse: 0.9136 - val_correlation: 0.1466 - val_student_loss: 0.7406\n",
      "Epoch 92/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9064 - correlation: 0.1746 - student_loss: 0.8216 - distillation_loss: 4.9446e-04 - val_rmse: 0.9136 - val_correlation: 0.1465 - val_student_loss: 0.7407\n",
      "Epoch 93/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1746 - student_loss: 0.8215 - distillation_loss: 4.9614e-04 - val_rmse: 0.9136 - val_correlation: 0.1465 - val_student_loss: 0.7406\n",
      "Epoch 94/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9064 - correlation: 0.1744 - student_loss: 0.8216 - distillation_loss: 4.9642e-04 - val_rmse: 0.9136 - val_correlation: 0.1466 - val_student_loss: 0.7406\n",
      "Epoch 95/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 4.9464e-04 - val_rmse: 0.9136 - val_correlation: 0.1466 - val_student_loss: 0.7406\n",
      "Epoch 96/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1746 - student_loss: 0.8216 - distillation_loss: 4.9667e-04 - val_rmse: 0.9136 - val_correlation: 0.1466 - val_student_loss: 0.7406\n",
      "Epoch 97/140\n",
      "2046/2046 [==============================] - 29s 14ms/step - rmse: 0.9064 - correlation: 0.1742 - student_loss: 0.8216 - distillation_loss: 4.9544e-04 - val_rmse: 0.9135 - val_correlation: 0.1467 - val_student_loss: 0.7405\n",
      "Epoch 98/140\n",
      "2046/2046 [==============================] - 25s 12ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 4.9778e-04 - val_rmse: 0.9135 - val_correlation: 0.1468 - val_student_loss: 0.7405\n",
      "Epoch 99/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1744 - student_loss: 0.8216 - distillation_loss: 4.9753e-04 - val_rmse: 0.9135 - val_correlation: 0.1468 - val_student_loss: 0.7405\n",
      "Epoch 100/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9064 - correlation: 0.1744 - student_loss: 0.8216 - distillation_loss: 4.9637e-04 - val_rmse: 0.9135 - val_correlation: 0.1469 - val_student_loss: 0.7405\n",
      "Epoch 101/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 4.9416e-04 - val_rmse: 0.9135 - val_correlation: 0.1469 - val_student_loss: 0.7405\n",
      "Epoch 102/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1747 - student_loss: 0.8215 - distillation_loss: 4.9607e-04 - val_rmse: 0.9135 - val_correlation: 0.1469 - val_student_loss: 0.7405\n",
      "Epoch 103/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1744 - student_loss: 0.8216 - distillation_loss: 4.9580e-04 - val_rmse: 0.9135 - val_correlation: 0.1469 - val_student_loss: 0.7405\n",
      "Epoch 104/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1746 - student_loss: 0.8215 - distillation_loss: 4.9608e-04 - val_rmse: 0.9135 - val_correlation: 0.1469 - val_student_loss: 0.7405\n",
      "Epoch 105/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9064 - correlation: 0.1746 - student_loss: 0.8216 - distillation_loss: 4.9700e-04 - val_rmse: 0.9135 - val_correlation: 0.1469 - val_student_loss: 0.7405\n",
      "Epoch 106/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1744 - student_loss: 0.8216 - distillation_loss: 4.9670e-04 - val_rmse: 0.9135 - val_correlation: 0.1469 - val_student_loss: 0.7405\n",
      "Epoch 107/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8215 - distillation_loss: 4.9423e-04 - val_rmse: 0.9135 - val_correlation: 0.1469 - val_student_loss: 0.7405\n",
      "Epoch 108/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 4.9525e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7405\n",
      "Epoch 109/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 4.9767e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7405\n",
      "Epoch 110/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1746 - student_loss: 0.8215 - distillation_loss: 4.9721e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7405\n",
      "Epoch 111/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 4.9232e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7405\n",
      "Epoch 112/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9064 - correlation: 0.1746 - student_loss: 0.8215 - distillation_loss: 4.9808e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7405\n",
      "Epoch 113/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1746 - student_loss: 0.8215 - distillation_loss: 4.9954e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7405\n",
      "Epoch 114/140\n",
      "2046/2046 [==============================] - 25s 12ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 4.9436e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7405\n",
      "Epoch 115/140\n",
      "2046/2046 [==============================] - 28s 14ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 4.9316e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7405\n",
      "Epoch 116/140\n",
      "2046/2046 [==============================] - 22s 11ms/step - rmse: 0.9064 - correlation: 0.1747 - student_loss: 0.8215 - distillation_loss: 4.9666e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 117/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8215 - distillation_loss: 4.9102e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7405\n",
      "Epoch 118/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1748 - student_loss: 0.8215 - distillation_loss: 4.9558e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 119/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 4.9426e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 120/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 4.9693e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 121/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8215 - distillation_loss: 4.9814e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 122/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 4.9549e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 123/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9064 - correlation: 0.1748 - student_loss: 0.8215 - distillation_loss: 5.0084e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 124/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1746 - student_loss: 0.8215 - distillation_loss: 4.9798e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 125/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 4.9319e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 126/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1748 - student_loss: 0.8215 - distillation_loss: 4.9457e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 127/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 4.9634e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 128/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1742 - student_loss: 0.8216 - distillation_loss: 4.9546e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 129/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1746 - student_loss: 0.8215 - distillation_loss: 4.9360e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 130/140\n",
      "2046/2046 [==============================] - 20s 10ms/step - rmse: 0.9064 - correlation: 0.1746 - student_loss: 0.8215 - distillation_loss: 4.9528e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 131/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1747 - student_loss: 0.8215 - distillation_loss: 4.9855e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 132/140\n",
      "2046/2046 [==============================] - 28s 14ms/step - rmse: 0.9064 - correlation: 0.1744 - student_loss: 0.8216 - distillation_loss: 4.9601e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 133/140\n",
      "2046/2046 [==============================] - 30s 15ms/step - rmse: 0.9064 - correlation: 0.1744 - student_loss: 0.8216 - distillation_loss: 4.9747e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 134/140\n",
      "2046/2046 [==============================] - 23s 11ms/step - rmse: 0.9064 - correlation: 0.1747 - student_loss: 0.8215 - distillation_loss: 4.9806e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 135/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1746 - student_loss: 0.8215 - distillation_loss: 4.9615e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 136/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1744 - student_loss: 0.8216 - distillation_loss: 4.9442e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 137/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1743 - student_loss: 0.8216 - distillation_loss: 4.9631e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 138/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1744 - student_loss: 0.8216 - distillation_loss: 4.9752e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 139/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 4.9682e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Epoch 140/140\n",
      "2046/2046 [==============================] - 21s 10ms/step - rmse: 0.9064 - correlation: 0.1745 - student_loss: 0.8216 - distillation_loss: 4.9847e-04 - val_rmse: 0.9135 - val_correlation: 0.1470 - val_student_loss: 0.7404\n",
      "Pearson: 0.14829912885432017\n",
      "CPU times: user 3h 9min 5s, sys: 24min 57s, total: 3h 34min 2s\n",
      "Wall time: 3h 36min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(3, shuffle=True, random_state=1997)\n",
    "models = []\n",
    "weights = []\n",
    "\n",
    "def lr_scheduler(epoch, lr):\n",
    "    decay_rate = 0.5\n",
    "    decay_step = 8\n",
    "    if epoch % decay_step == 0 and epoch:\n",
    "        return lr * decay_rate\n",
    "    return lr\n",
    "\n",
    "for index, (train_indices, valid_indices) in enumerate(kfold.split(train, investment_id)):\n",
    "#     break\n",
    "    valid_indices = valid_indices[:800700]\n",
    "#     print(len(train_indices))\n",
    "    X_train, X_val = train.iloc[train_indices], train.iloc[valid_indices]\n",
    "    investment_id_train = investment_id[train_indices]\n",
    "    y_train, y_val = y.iloc[train_indices], y.iloc[valid_indices]\n",
    "    investment_id_val = investment_id[valid_indices]\n",
    "    train_ds = make_dataset(X_train, investment_id_train, y_train)\n",
    "    valid_ds = make_dataset(X_val, investment_id_val, y_val, mode=\"valid\")\n",
    "    \n",
    "    student = get_model2()\n",
    "    distiller = Distiller(student=student, teacher=teacher)\n",
    "    # Compile Distiller model\n",
    "    rmse = keras.metrics.RootMeanSquaredError(name=\"rmse\")\n",
    "    distiller.compile(\n",
    "        student_loss_fn=keras.losses.MeanSquaredError(),\n",
    "\n",
    "        optimizer=tf.optimizers.Adam(0.001),\n",
    "        metrics=[rmse, correlation],\n",
    "        distillation_loss_fn=keras.losses.MeanSquaredError(reduction=\"auto\", name=\"mse\"),\n",
    "        alpha=0.05,\n",
    "        temperature=1)\n",
    "\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(f\"dess_{index}\", save_best_only=True)\n",
    "    early_stop = keras.callbacks.EarlyStopping(patience=8)\n",
    "    shedualer = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "    \n",
    "    history = distiller.fit(train_ds, epochs=140, validation_data=valid_ds, callbacks=[checkpoint, early_stop, shedualer])\n",
    "    \n",
    "#     models.append(keras.models.load_model(f\"model_{index}\"))\n",
    "\n",
    "    model = distiller.student\n",
    "    \n",
    "    pearson_score = stats.pearsonr(model.predict(valid_ds).ravel(), y_val.values)[0]\n",
    "    \n",
    "    model.save(f\"dess_{index}\")\n",
    "    models.append(model)\n",
    "    weights.append(pearson_score)\n",
    "    \n",
    "    print('Pearson:', pearson_score)\n",
    "#     pd.DataFrame(history.history, columns=[\"mse\", \"val_mse\"]).plot()\n",
    "#     plt.title(\"MSE\")\n",
    "#     plt.show()\n",
    "# #     pd.DataFrame(history.history, columns=[\"mae\", \"val_mae\"]).plot()\n",
    "# #     plt.title(\"MAE\")\n",
    "# #     plt.show()\n",
    "#     pd.DataFrame(history.history, columns=[\"correlation\", \"val_correlation\"]).plot()\n",
    "#     plt.title(\"correlation\")\n",
    "#     plt.show()\n",
    "    del investment_id_train\n",
    "    del investment_id_val\n",
    "    del X_train\n",
    "    del X_val\n",
    "    del y_train\n",
    "    del y_val\n",
    "    del train_ds\n",
    "    del valid_ds\n",
    "    gc.collect()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb0db482",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T11:15:20.818581Z",
     "iopub.status.busy": "2022-03-26T11:15:20.817828Z",
     "iopub.status.idle": "2022-03-26T11:15:20.820961Z",
     "shell.execute_reply": "2022-03-26T11:15:20.821432Z",
     "shell.execute_reply.started": "2022-03-26T07:35:11.484555Z"
    },
    "papermill": {
     "duration": 40.930973,
     "end_time": "2022-03-26T11:15:20.821606",
     "exception": false,
     "start_time": "2022-03-26T11:14:39.890633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3338101835693534, 0.334735387510482, 0.3314544289201647]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = list(np.array(weights)/sum(weights))\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8587bf96",
   "metadata": {
    "papermill": {
     "duration": 40.835975,
     "end_time": "2022-03-26T11:16:42.855129",
     "exception": false,
     "start_time": "2022-03-26T11:16:02.019154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8aa1a1fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T11:18:05.096984Z",
     "iopub.status.busy": "2022-03-26T11:18:05.095342Z",
     "iopub.status.idle": "2022-03-26T11:18:05.097546Z",
     "shell.execute_reply": "2022-03-26T11:18:05.097984Z",
     "shell.execute_reply.started": "2022-03-26T07:35:11.495999Z"
    },
    "papermill": {
     "duration": 41.213993,
     "end_time": "2022-03-26T11:18:05.098122",
     "exception": false,
     "start_time": "2022-03-26T11:17:23.884129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_test(investment_id, feature):\n",
    "    return (investment_id, feature), 0\n",
    "def make_test_dataset(feature, investment_id, batch_size=1024):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(((investment_id, feature)))\n",
    "    ds = ds.map(preprocess_test)\n",
    "    ds = ds.batch(batch_size).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds\n",
    "def inference(models, ds):\n",
    "    y_preds = []\n",
    "    for model, w in zip(models, weights):\n",
    "        y_pred = model.predict(ds)\n",
    "        y_preds.append(y_pred*w)\n",
    "    return np.sum(y_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b29360c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T11:19:27.539019Z",
     "iopub.status.busy": "2022-03-26T11:19:27.538400Z",
     "iopub.status.idle": "2022-03-26T11:19:28.448191Z",
     "shell.execute_reply": "2022-03-26T11:19:28.447671Z",
     "shell.execute_reply.started": "2022-03-26T07:35:11.507583Z"
    },
    "papermill": {
     "duration": 42.165342,
     "end_time": "2022-03-26T11:19:28.448369",
     "exception": false,
     "start_time": "2022-03-26T11:18:46.283027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "import ubiquant\n",
    "env = ubiquant.make_env()\n",
    "iter_test = env.iter_test() \n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    ds = make_test_dataset(test_df[features], test_df[\"investment_id\"])\n",
    "    sample_prediction_df['target'] = inference(models, ds)\n",
    "    env.predict(sample_prediction_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905178ee",
   "metadata": {
    "papermill": {
     "duration": 41.513268,
     "end_time": "2022-03-26T11:20:50.960411",
     "exception": false,
     "start_time": "2022-03-26T11:20:09.447143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13475.400163,
   "end_time": "2022-03-26T11:21:34.617303",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-26T07:36:59.217140",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
